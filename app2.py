import streamlit as st
from openai import OpenAI
import json
from datetime import datetime, timezone   # [ADD] timezone
import re
import os                                  # [ADD]
import uuid                                # [ADD]
import csv                                  # [ADD]
import time

LOG_DIR = "logs"
LOG_FILE = os.path.join(LOG_DIR, "events.csv")

# [ADD] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê°„ë‹¨í•œ ì„¸ì…˜/ìœ ì € ì‹ë³„ì (ë¡œê·¸ì¸ ì „ MVP)
if "session_id" not in st.session_state:
    st.session_state.session_id = f"sess_{uuid.uuid4().hex[:12]}"


# ===== ìµëª… user_id ìƒì„±/ìœ ì§€ (MVP: URL uid + ë¡œì»¬ íŒŒì¼ ìºì‹œ) =====
USER_FILE = os.path.join(LOG_DIR, "user_info.json")

def _read_local_user_id():
    try:
        if os.path.exists(USER_FILE):
            with open(USER_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                return data.get("user_id")
    except Exception:
        pass
    return None

def _write_local_user_id(uid: str):
    try:
        os.makedirs(LOG_DIR, exist_ok=True)
        with open(USER_FILE, "w", encoding="utf-8") as f:
            json.dump({"user_id": uid, "created_at": now_utc_iso(), "user_type": "anonymous"}, f, ensure_ascii=False)
    except Exception:
        pass

def get_or_create_user_id() -> str:
    # 1) URL ì¿¼ë¦¬íŒŒë¼ë¯¸í„° ìš°ì„  (Streamlit 1.30+)
    try:
        uid_from_qs = st.query_params.get("uid", None)
    except Exception:
        uid_from_qs = None
        try:
            qs = st.experimental_get_query_params()
            if "uid" in qs:
                uid_from_qs = qs["uid"][0]
        except Exception:
            pass

    if uid_from_qs:
        return uid_from_qs

    # 2) ë¡œì»¬ íŒŒì¼ ìºì‹œ (ê°œë°œ/MVP í™˜ê²½ì—ì„œ ìœ íš¨)
    uid_local = _read_local_user_id()
    if uid_local:
        # URLì— uidê°€ ì—†ìœ¼ë©´ ë‹¬ì•„ì¤Œ(ìƒˆë¡œê³ ì¹¨ ì—†ì´ URLë§Œ ì •ë¦¬)
        try:
            st.query_params["uid"] = uid_local
        except Exception:
            try:
                st.experimental_set_query_params(uid=uid_local)
            except Exception:
                pass
        return uid_local

    # 3) ì‹ ê·œ ìƒì„±
    new_uid = f"user_{uuid.uuid4().hex[:8]}"
    _write_local_user_id(new_uid)
    # URLì—ë„ ë°˜ì˜
    try:
        st.query_params["uid"] = new_uid
    except Exception:
        try:
            st.experimental_set_query_params(uid=new_uid)
        except Exception:
            pass
    return new_uid

# ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ë°”ì¸ë”©
if "user_id" not in st.session_state:
    st.session_state.user_id = get_or_create_user_id()

# =============================================================

# âœ… [ì¶”ê°€ 1] í˜ì´ì§€ ì²´ë¥˜ì‹œê°„ ê¸°ë¡ìš© ì‹œì‘ì  ì €ì¥
if "page_enter_time" not in st.session_state:
    st.session_state.page_enter_time = datetime.now()

# âœ… [ì¶”ê°€ 2] ìš©ì–´ í´ë¦­ ëˆ„ì  ì¹´ìš´í„°
if "term_click_count" not in st.session_state:
    st.session_state.term_click_count = 0    

def now_utc_iso() -> str:
    return datetime.now(timezone.utc).isoformat()


def ensure_log_file():
    os.makedirs(LOG_DIR, exist_ok=True)
    if not os.path.exists(LOG_FILE):
        with open(LOG_FILE, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(
                f,
                fieldnames=[
                    "event_time","event_name","user_id","session_id",
                    "news_id","term","source","surface",
                    "message","payload_json"
                ]
            )
            writer.writeheader()

def log_event(event_name: str, **kwargs):
    """
    CSV ê¸°ë°˜ MVP ë¡œê¹….
    í‘œì¤€ ì»¬ëŸ¼ + ìœ ì—°í•œ payload_jsonì— ê¸°íƒ€ ì •ë³´ë¥¼ ë„£ëŠ”ë‹¤.
    """
    ensure_log_file()
    row = {
        "event_time": now_utc_iso(),
        "event_name": event_name,
        "user_id": st.session_state.get("user_id","anon"),
        "session_id": st.session_state.get("session_id"),
        # ì„ íƒì  ì»¨í…ìŠ¤íŠ¸ (ì—†ìœ¼ë©´ ë¹ˆ ê°’)
        "news_id": kwargs.get("news_id",""),
        "term": kwargs.get("term",""),
        "source": kwargs.get("source",""),
        "surface": kwargs.get("surface",""),
        "message": kwargs.get("message",""),
        # ë‚˜ë¨¸ì§€ëŠ” payload_jsonìœ¼ë¡œ ì§ë ¬í™”
        "payload_json": json.dumps(kwargs.get("payload",{}), ensure_ascii=False),
    }
    with open(LOG_FILE, "a", newline="", encoding="utf-8") as f:
        csv.DictWriter(f, fieldnames=row.keys()).writerow(row)
# [ADD] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€



# í˜ì´ì§€ ì„¤ì •
st.set_page_config(layout="wide", page_title="ê¸ˆìœµ ë‰´ìŠ¤ ë„ìš°ë¯¸")

# [ADD] ì„¸ì…˜ ì‹œì‘ ë¡œê·¸ (ìµœì´ˆ 1íšŒ)
# ì°¸ê³ : uaëŠ” Streamlitì—ì„œ ì§ì ‘ ëª» ë½‘ìœ¼ë‹ˆ, MVPì—ì„  ë¹ˆ dictë¡œ ë‚¨ì•„ë„ ë¬´ë°©. (GA4 ë¶™ì¼ ë•Œ ê°œì„ )
if "session_logged" not in st.session_state:
    log_event(
        "session_start",
        surface="home",
        payload={"ua": st.session_state.get("_browser",{}), "note":"MVP session start"}
    )
    st.session_state.session_logged = True

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (MVP ë‹¨ê³„: Mock ëª¨ë“œ)
USE_OPENAI = False  # API ì—°ê²° ì‹œ Trueë¡œ ë³€ê²½

@st.cache_resource
def get_openai_client():
    if USE_OPENAI:
        api_key = st.secrets.get("OPENAI_API_KEY", "your-api-key-here")
        return OpenAI(api_key=api_key)
    return None

client = get_openai_client()

# ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì´ˆê¸°í™”
if 'news_articles' not in st.session_state:
    st.session_state.news_articles = []
if 'selected_article' not in st.session_state:
    st.session_state.selected_article = None
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'financial_terms' not in st.session_state:
    # RAGë¥¼ ìœ„í•œ ê¸ˆìœµ ìš©ì–´ ì‚¬ì „ (ì˜ˆì‹œ)
    st.session_state.financial_terms = {
        "ì–‘ì ì™„í™”": {
            "ì •ì˜": "ì¤‘ì•™ì€í–‰ì´ ì‹œì¤‘ì— í†µí™”ë¥¼ ê³µê¸‰í•˜ê¸° ìœ„í•´ êµ­ì±„ ë“±ì„ ë§¤ì…í•˜ëŠ” ì •ì±…",
            "ì„¤ëª…": "ê²½ê¸° ë¶€ì–‘ì„ ìœ„í•´ ì¤‘ì•™ì€í–‰ì´ ëˆì„ í’€ì–´ ì‹œì¥ ìœ ë™ì„±ì„ ë†’ì´ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.",
            "ë¹„ìœ ": "ë§ˆë¥¸ ë•…ì— ë¬¼ì„ ë¿Œë ¤ì£¼ëŠ” ê²ƒì²˜ëŸ¼, ê²½ì œì— ëˆì´ë¼ëŠ” ë¬¼ì„ ê³µê¸‰í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤."
        },
        "ê¸°ì¤€ê¸ˆë¦¬": {
            "ì •ì˜": "ì¤‘ì•™ì€í–‰ì´ ì‹œì¤‘ì€í–‰ì— ëˆì„ ë¹Œë ¤ì¤„ ë•Œ ì ìš©í•˜ëŠ” ê¸°ì¤€ì´ ë˜ëŠ” ê¸ˆë¦¬",
            "ì„¤ëª…": "ëª¨ë“  ê¸ˆë¦¬ì˜ ê¸°ì¤€ì´ ë˜ë©°, ê¸°ì¤€ê¸ˆë¦¬ê°€ ì˜¤ë¥´ë©´ ëŒ€ì¶œì´ìë„ í•¨ê»˜ ì˜¤ë¦…ë‹ˆë‹¤.",
            "ë¹„ìœ ": "ë¬¼ê°€ì˜ ì˜¨ë„ì¡°ì ˆê¸°ì™€ ê°™ìŠµë‹ˆë‹¤. ê²½ì œê°€ ê³¼ì—´ë˜ë©´ ì˜¬ë¦¬ê³ , ì¹¨ì²´ë˜ë©´ ë‚´ë¦½ë‹ˆë‹¤."
        },
        "ë°°ë‹¹": {
            "ì •ì˜": "ê¸°ì—…ì´ ë²Œì–´ë“¤ì¸ ì´ìµ ì¤‘ ì¼ë¶€ë¥¼ ì£¼ì£¼ë“¤ì—ê²Œ ë‚˜ëˆ ì£¼ëŠ” ê²ƒ",
            "ì„¤ëª…": "ì£¼ì‹ì„ ë³´ìœ í•œ ì£¼ì£¼ì—ê²Œ ê¸°ì—…ì˜ ì´ìµì„ ë¶„ë°°í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.",
            "ë¹„ìœ ": "í•¨ê»˜ ì‹ë‹¹ì„ ìš´ì˜í•˜ëŠ” ë™ì—…ìë“¤ì´ ë§¤ì¶œ ì¤‘ ì¼ë¶€ë¥¼ ë‚˜ëˆ ê°–ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤."
        },
        "PER": {
            "ì •ì˜": "ì£¼ê°€ìˆ˜ìµë¹„ìœ¨. ì£¼ê°€ë¥¼ ì£¼ë‹¹ìˆœì´ìµìœ¼ë¡œ ë‚˜ëˆˆ ê°’",
            "ì„¤ëª…": "ì£¼ì‹ì´ 1ë…„ ì¹˜ ì´ìµì˜ ëª‡ ë°°ì— ê±°ë˜ë˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë‚®ì„ìˆ˜ë¡ ì €í‰ê°€ëœ ê²ƒìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "ë¹„ìœ ": "1ë…„ì— 100ë§Œì› ë²„ëŠ” ê°€ê²Œë¥¼ ëª‡ ë…„ ì¹˜ ìˆ˜ìµì„ ì£¼ê³  ì‚¬ëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤."
        },
        "í™˜ìœ¨": {
            "ì •ì˜": "ì„œë¡œ ë‹¤ë¥¸ ë‘ ë‚˜ë¼ í™”íì˜ êµí™˜ ë¹„ìœ¨",
            "ì„¤ëª…": "ì›í™”ë¥¼ ë‹¬ëŸ¬ë¡œ, ë‹¬ëŸ¬ë¥¼ ì›í™”ë¡œ ë°”ê¿€ ë•Œ ì ìš©ë˜ëŠ” ë¹„ìœ¨ì…ë‹ˆë‹¤.",
            "ë¹„ìœ ": "í•´ì™¸ ì‡¼í•‘ëª°ì—ì„œ ë¬¼ê±´ì„ ì‚´ ë•Œ ì ìš©ë˜ëŠ” í™˜ì „ ë¹„ìœ¨ì…ë‹ˆë‹¤."
        }
    }

# ë‰´ìŠ¤ ìˆ˜ì§‘ Agent (ì‹œë®¬ë ˆì´ì…˜)
def collect_news():
    """ì‹¤ì œë¡œëŠ” OpenAI APIë¡œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œ ë°ì´í„° ì‚¬ìš©"""
    sample_news = [
        {
            "id": 1,
            "title": "í•œêµ­ì€í–‰, ê¸°ì¤€ê¸ˆë¦¬ ë™ê²° ê²°ì •",
            "summary": "í•œêµ­ì€í–‰ì´ ë¬¼ê°€ ì•ˆì •ì„ ìœ„í•´ ê¸°ì¤€ê¸ˆë¦¬ë¥¼ í˜„ ìˆ˜ì¤€ìœ¼ë¡œ ìœ ì§€í•˜ê¸°ë¡œ í–ˆìŠµë‹ˆë‹¤.",
            "content": "í•œêµ­ì€í–‰ ê¸ˆìœµí†µí™”ìœ„ì›íšŒëŠ” 21ì¼ íšŒì˜ë¥¼ ì—´ê³  ê¸°ì¤€ê¸ˆë¦¬ë¥¼ ì—° 3.50%ë¡œ ë™ê²°í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ìµœê·¼ ë¬¼ê°€ ìƒìŠ¹ì„¸ê°€ ì§„ì •ë˜ê³  ìˆìœ¼ë‚˜ ì—¬ì „íˆ ë¶ˆí™•ì‹¤ì„±ì´ í¬ë‹¤ëŠ” íŒë‹¨ì— ë”°ë¥¸ ê²ƒì…ë‹ˆë‹¤. ì‹œì¥ì—ì„œëŠ” ì–‘ì ì™„í™” ì •ì±… ì „í™˜ ê°€ëŠ¥ì„±ë„ ì œê¸°ë˜ê³  ìˆìŠµë‹ˆë‹¤.",
            "date": "2025-10-21"
        },
        {
            "id": 2,
            "title": "ì‚¼ì„±ì „ì, ë¶„ê¸° ë°°ë‹¹ 20% ì¦ì•¡ ë°œí‘œ",
            "summary": "ì‚¼ì„±ì „ìê°€ ì£¼ì£¼í™˜ì› ì •ì±… ê°•í™” ì¼í™˜ìœ¼ë¡œ ë°°ë‹¹ê¸ˆì„ ëŒ€í­ ëŠ˜ë ¸ìŠµë‹ˆë‹¤.",
            "content": "ì‚¼ì„±ì „ìëŠ” ì´ë²ˆ ë¶„ê¸° ë°°ë‹¹ì„ ì£¼ë‹¹ 500ì›ìœ¼ë¡œ ê²°ì •í•˜ë©° ì „ë…„ ë™ê¸° ëŒ€ë¹„ 20% ì¦ì•¡í–ˆìŠµë‹ˆë‹¤. PERì´ í•˜ë½í•˜ë©° ì£¼ê°€ê°€ ì €í‰ê°€ëë‹¤ëŠ” ì‹œì¥ ë¶„ì„ì— ë”°ë¼ ì£¼ì£¼í™˜ì›ì„ ê°•í™”í•˜ê² ë‹¤ëŠ” ì˜ì§€ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.",
            "date": "2025-10-20"
        },
        {
            "id": 3,
            "title": "ì›ë‹¬ëŸ¬ í™˜ìœ¨, 1,300ì› ëŒíŒŒ",
            "summary": "ë¯¸êµ­ ê¸ˆë¦¬ ì¸ìƒ ì˜í–¥ìœ¼ë¡œ ì›í™” ê°€ì¹˜ê°€ ì•½ì„¸ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.",
            "content": "21ì¼ ì„œìš¸ ì™¸í™˜ì‹œì¥ì—ì„œ ì›ë‹¬ëŸ¬ í™˜ìœ¨ì´ 1,300ì›ì„ ë„˜ì–´ì„°ìŠµë‹ˆë‹¤. ë¯¸êµ­ì˜ ê¸°ì¤€ê¸ˆë¦¬ ì¸ìƒ ê¸°ì¡°ê°€ ì§€ì†ë˜ë©´ì„œ ë‹¬ëŸ¬ ê°•ì„¸ê°€ ì´ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤. ìˆ˜ì¶œ ê¸°ì—…ë“¤ì—ê²ŒëŠ” í˜¸ì¬ì´ì§€ë§Œ ìˆ˜ì… ë¬¼ê°€ ìƒìŠ¹ ìš°ë ¤ë„ ì»¤ì§€ê³  ìˆìŠµë‹ˆë‹¤.",
            "date": "2025-10-21"
        }
    ]
    return sample_news

# ë‰´ìŠ¤ ìš”ì•½ ìƒì„± (GPT-4o-mini ì‚¬ìš©)
def generate_summary(articles):
    """ì—¬ëŸ¬ ë‰´ìŠ¤ë¥¼ ì¢…í•©í•œ ìš”ì•½ ìƒì„±"""
    if USE_OPENAI and client:
        try:
            news_texts = "\n\n".join([f"ì œëª©: {a['title']}\në‚´ìš©: {a['content']}" for a in articles])
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸ˆìœµ ë‰´ìŠ¤ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": f"ë‹¤ìŒ ê¸ˆìœµ ë‰´ìŠ¤ë“¤ì„ 3-4ë¬¸ì¥ìœ¼ë¡œ ì¢…í•© ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{news_texts}"}
                ],
                max_tokens=200
            )
            return response.choices[0].message.content
        except:
            pass
    
    # Mock ì‘ë‹µ (API ë¯¸ì—°ê²° ì‹œ)
    return "ì˜¤ëŠ˜ ê¸ˆìœµ ì‹œì¥ì€ í•œêµ­ì€í–‰ì˜ ê¸°ì¤€ê¸ˆë¦¬ ë™ê²° ê²°ì •ê³¼ ì‚¼ì„±ì „ìì˜ ë°°ë‹¹ ì¦ì•¡ ë°œí‘œê°€ ì£¼ëª©ë°›ì•˜ìŠµë‹ˆë‹¤. ì›ë‹¬ëŸ¬ í™˜ìœ¨ì´ 1,300ì›ì„ ëŒíŒŒí•˜ë©° ì™¸í™˜ì‹œì¥ì˜ ë³€ë™ì„±ë„ ì»¤ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì „ë¬¸ê°€ë“¤ì€ í–¥í›„ í†µí™”ì •ì±… ë°©í–¥ê³¼ í™˜ìœ¨ ì¶”ì´ë¥¼ ì£¼ì‹œí•  í•„ìš”ê°€ ìˆë‹¤ê³  ì¡°ì–¸í•©ë‹ˆë‹¤."

# ìš©ì–´ í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬
def highlight_terms(text, terms_dict):
    """í…ìŠ¤íŠ¸ì—ì„œ ê¸ˆìœµ ìš©ì–´ë¥¼ í•˜ì´ë¼ì´íŠ¸"""
    highlighted = text
    for term in terms_dict.keys():
        # HTMLë¡œ í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬ - í´ë¦­ ê°€ëŠ¥í•˜ë„ë¡
        pattern = re.compile(re.escape(term), re.IGNORECASE)
        highlighted = pattern.sub(
            f'<mark class="clickable-term" data-term="{term}" style="background-color: #FFEB3B; cursor: pointer; padding: 2px 4px; border-radius: 3px;">{term}</mark>',
            highlighted
        )
    return highlighted

# RAG ê¸°ë°˜ ìš©ì–´ ì„¤ëª…
def explain_term(term, chat_history):
    """RAGë¥¼ ì‚¬ìš©í•˜ì—¬ ìš©ì–´ ì„¤ëª…"""
    if term in st.session_state.financial_terms:
        term_info = st.session_state.financial_terms[term]
        context = f"""
        ìš©ì–´: {term}
        ì •ì˜: {term_info['ì •ì˜']}
        ì„¤ëª…: {term_info['ì„¤ëª…']}
        ë¹„ìœ : {term_info['ë¹„ìœ ']}
        """
        
        if USE_OPENAI and client:
            try:
                messages = [
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸ˆìœµ ìš©ì–´ë¥¼ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ì¹œì ˆí•œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ˆë³´ìë„ ì´í•´í•  ìˆ˜ ìˆê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."}
                ]
                
                # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì¶”ê°€
                for msg in chat_history[-4:]:  # ìµœê·¼ 4ê°œë§Œ
                    messages.append(msg)
                
                messages.append({
                    "role": "user", 
                    "content": f"ë‹¤ìŒ ê¸ˆìœµ ìš©ì–´ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”:\n{context}"
                })
                
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=messages,
                    max_tokens=300
                )
                return response.choices[0].message.content
            except:
                pass
        
        # Mock ì‘ë‹µ (API ë¯¸ì—°ê²° ì‹œ)
        return f"""**{term}** ì— ëŒ€í•´ ì„¤ëª…í•´ë“œë¦´ê²Œìš”! ğŸ¯

ğŸ“– **ì •ì˜**
{term_info['ì •ì˜']}

ğŸ’¡ **ì‰¬ìš´ ì„¤ëª…**
{term_info['ì„¤ëª…']}

ğŸŒŸ **ë¹„ìœ ë¡œ ì´í•´í•˜ê¸°**
{term_info['ë¹„ìœ ']}

ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!"""
    else:
        return f"'{term}'ì— ëŒ€í•œ ì •ë³´ê°€ ê¸ˆìœµ ì‚¬ì „ì— ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ìš©ì–´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .news-card {
        padding: 15px;
        border-radius: 10px;
        border: 1px solid #ddd;
        margin: 10px 0;
        cursor: pointer;
        transition: all 0.3s;
    }
    .news-card:hover {
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        border-color: #1f77b4;
    }
    .summary-box {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 20px;
        border-radius: 15px;
        margin-bottom: 20px;
    }
    .article-content {
        background: #f9f9f9;
        padding: 20px;
        border-radius: 10px;
        line-height: 1.8;
    }
    .chat-message {
        padding: 10px;
        border-radius: 10px;
        margin: 5px 0;
    }
    .user-message {
        background: #e3f2fd;
        text-align: right;
    }
    .bot-message {
        background: #f5f5f5;
    }
    .clickable-term {
        transition: all 0.2s;
    }
    .clickable-term:hover {
        background-color: #FDD835 !important;
        transform: scale(1.05);
    }
</style>
""", unsafe_allow_html=True)

# ë©”ì¸ ë ˆì´ì•„ì›ƒ
col1, col2 = st.columns([2, 1])

# ì™¼ìª½: ì»¨í…ì¸  ì˜ì—­
with col1:
    st.title("ğŸ“° ê¸ˆìœµ ë‰´ìŠ¤ ë„ìš°ë¯¸")
    
    # ë‰´ìŠ¤ ìˆ˜ì§‘
    if not st.session_state.news_articles:
        with st.spinner("ìµœì‹  ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì¤‘..."):
            st.session_state.news_articles = collect_news()
    
    # ì„ íƒëœ ê¸°ì‚¬ê°€ ì—†ì„ ë•Œ: ìš”ì•½ + ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
    if st.session_state.selected_article is None:
        # ì¢…í•© ìš”ì•½
        st.markdown('<div class="summary-box">', unsafe_allow_html=True)
        st.subheader("ğŸ“Š ì˜¤ëŠ˜ì˜ ê¸ˆìœµ ë‰´ìŠ¤ ìš”ì•½")
        summary = generate_summary(st.session_state.news_articles)
        st.write(summary)
        st.markdown('</div>', unsafe_allow_html=True)
        
        # ë‰´ìŠ¤ ëª©ë¡
        st.subheader("ğŸ“‹ ìµœì‹  ë‰´ìŠ¤")
        for article in st.session_state.news_articles:
            if st.button(
                f"**{article['title']}**\n{article['summary']}", 
                key=f"news_{article['id']}",
                use_container_width=True
            ):
                # ë‰´ìŠ¤ í´ë¦­ ë¡œê·¸
                log_event(
                    "news_click",
                    news_id=article.get("id"),
                    source="list",
                    surface="home",
                    payload={"title": article.get("title")}
                )
                st.session_state.selected_article = article
                st.rerun()
    
        # -----------------------------------------
        # ë‰´ìŠ¤ ìƒì„¸ í˜ì´ì§€ ì§„ì… 
        # -----------------------------------------

    else:
        article = st.session_state.selected_article

        # [ADD] ìƒì„¸ í™”ë©´ ì§„ì… ë¡œê·¸ (ì¤‘ë³µ ë°©ì§€)
        if not st.session_state.get("detail_enter_logged"):
            log_event(
                "news_detail_open",
                news_id=article.get("id"),
                surface="detail",
                payload={"title": article.get("title")}
            )
            st.session_state.detail_enter_logged = True
            st.session_state.page_enter_time = datetime.now()

    if st.button("â† ë‰´ìŠ¤ ëª©ë¡ìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        # [ADD] ìƒì„¸ í™”ë©´ ì´íƒˆ ë¡œê·¸
        log_event(
            "news_detail_back",
            news_id=article.get("id"),
            surface="detail"
        )
        st.session_state.selected_article = None
        st.session_state.detail_enter_logged = False
        st.rerun()
        
    st.markdown("---")
    st.header(article['title'])
    st.caption(f"ğŸ“… {article['date']}")
    
    # ìš©ì–´ í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬ëœ ë³¸ë¬¸
    st.markdown('<div class="article-content">', unsafe_allow_html=True)
    highlighted_content = highlight_terms(article['content'], st.session_state.financial_terms)
    st.markdown(highlighted_content, unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)
    
    st.info("ğŸ’¡ ì•„ë˜ ë²„íŠ¼ì—ì„œ ìš©ì–´ë¥¼ ì„ íƒí•˜ë©´ ì±—ë´‡ì´ ì‰½ê²Œ ì„¤ëª…í•´ë“œë¦½ë‹ˆë‹¤!")
    
    # ìš©ì–´ ì„ íƒ ë²„íŠ¼ - í° ë²„íŠ¼ìœ¼ë¡œ ê°œì„ 
    st.subheader("ğŸ” ìš©ì–´ ì„¤ëª… ìš”ì²­")
    terms_in_article = [term for term in st.session_state.financial_terms.keys() if term in article['content']]
    
    # í•œ ì¤„ì— 3ê°œì”© ë°°ì¹˜
    for i in range(0, len(terms_in_article), 3):
        cols = st.columns(3)
        for j, col in enumerate(cols):
            if i + j < len(terms_in_article):
                term = terms_in_article[i + j]
                with col:
                    if st.button(
                        f"ğŸ“Œ {term}", 
                        key=f"term_btn_{term}",
                        use_container_width=True,
                        type="secondary"
                    ):
                        # âœ… ìš©ì–´ í´ë¦­ ì¹´ìš´íŠ¸ ëˆ„ì  ë¡œê·¸
                        st.session_state.term_click_count += 1
                        # [ADD] Glossary ì¡°íšŒ ë¡œê·¸
                        log_event(
                            "glossary_click",
                            term=term,
                            news_id=article.get("id"),
                            source="news_highlight",
                            surface="detail",
                            payload={"click_count": st.session_state.term_click_count}
                        )

                        # ì±„íŒ…ì— ìš©ì–´ ì„¤ëª… ì¶”ê°€
                        user_msg = {"role": "user", "content": f"'{term}' ìš©ì–´ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”"}
                        st.session_state.chat_history.append(user_msg)

                        # ì±—ë´‡ ì‘ë‹µ ìƒì„±
                        explanation = explain_term(term, st.session_state.chat_history)
                        bot_msg = {"role": "assistant", "content": explanation}
                        st.session_state.chat_history.append(bot_msg)

                        # Glossary ì‘ë‹µ ë¡œê·¸
                        log_event(
                            "glossary_answer",
                            term=term,
                            source="news_highlight",
                            surface="detail",
                            payload={"answer_len": len(explanation)}
                        )

                        st.rerun()
    
    # í•˜ì´ë¼ì´íŠ¸ í´ë¦­ ê°ì§€ ì œê±° (Streamlit í•œê³„)
    st.caption("ğŸ’¡ Tip: ìœ„ ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ì˜¤ë¥¸ìª½ ì±—ë´‡ì—ì„œ ìƒì„¸í•œ ì„¤ëª…ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")

# ì˜¤ë¥¸ìª½: ì±—ë´‡ ì˜ì—­
with col2:
    st.markdown("### ğŸ’¬ ê¸ˆìœµ ìš©ì–´ ë„ìš°ë¯¸")
    st.markdown("---")
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    chat_container = st.container(height=400)
    with chat_container:
        for message in st.session_state.chat_history:
            if message["role"] == "user":
                st.markdown(f'<div class="chat-message user-message">ğŸ‘¤ {message["content"]}</div>', unsafe_allow_html=True)
            else:
                st.markdown(f'<div class="chat-message bot-message">ğŸ¤– {message["content"]}</div>', unsafe_allow_html=True)
    
    # ì‚¬ìš©ì ì…ë ¥
    # -----------------------------------------
    # ê¸°ì¡´ ì±—ë´‡ ì…ë ¥ ë¶€ë¶„ì— latency ë¡œê·¸ ì¶”ê°€
    # -----------------------------------------
    user_input = st.chat_input("ê¶ê¸ˆí•œ ê¸ˆìœµ ìš©ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")
    
    if user_input:
        start_time = time.time() # ì±—ë´‡ ì‘ë‹µì‹œê°„ ê¸°ë¡
        # [ADD] ì±„íŒ… ì§ˆì˜ ë¡œê·¸
        log_event(
            "chat_question",
            message=user_input,
            source="chat",
            surface="sidebar"
        )
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        
        # ìš©ì–´ ì¶”ì¶œ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­)
        found_term = None
        for term in st.session_state.financial_terms.keys():
            if term in user_input:
                found_term = term
                break
        
        if found_term:
            explanation = explain_term(found_term, st.session_state.chat_history)
        
            # [ADD] ìš©ì–´ ì§ˆì˜ì¸ ê²½ìš° glossary_answerë¡œë„ ë‚¨ê¹€
            log_event(
                "glossary_answer",
                term=found_term,
                source="chat",
                surface="sidebar",
                payload={"answer_len": len(explanation)}
            )

        else:
            # ì¼ë°˜ ëŒ€í™”
            if USE_OPENAI and client:
                try:
                    response = client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[
                            {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸ˆìœµ ìš©ì–´ë¥¼ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤."}
                        ] + st.session_state.chat_history,
                        max_tokens=300
                    )
                    explanation = response.choices[0].message.content
                except:
                    explanation = "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            else:
                # Mock ì‘ë‹µ
                explanation = f"'{user_input}'ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹œêµ°ìš”! MVP ê°œë°œ ë‹¨ê³„ì—ì„œëŠ” ê¸ˆìœµ ì‚¬ì „ì— ë“±ë¡ëœ ìš©ì–´({', '.join(st.session_state.financial_terms.keys())})ë§Œ ì„¤ëª…ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. í•´ë‹¹ ìš©ì–´ë¥¼ ì…ë ¥í•˜ì‹œê±°ë‚˜ ê¸°ì‚¬ì—ì„œ í•˜ì´ë¼ì´íŠ¸ëœ ìš©ì–´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”! ğŸ˜Š"

            latency = int((time.time() - start_time) * 1000)
            # âœ… ì‘ë‹µ ì‹œê°„ ê¸°ë¡
            log_event(
                "chat_response",
                source="chat",
                surface="sidebar",
                payload={
                    "answer_len": len(explanation),
                    "latency_ms": latency
                }
            )
        
        st.session_state.chat_history.append({"role": "assistant", "content": explanation})
        # [ADD] ì±—ë´‡ ì‘ë‹µ ë¡œê·¸
        log_event(
            "chat_response",
            source="chat",
            surface="sidebar",
            payload={"answer_len": len(explanation)}
        )
        
        st.rerun()
    
    # ì±„íŒ… ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”"):
        log_event("chat_reset", surface="sidebar")
        st.session_state.chat_history = []
        st.rerun()

# ì‚¬ì´ë“œë°”: ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    st.markdown("---")
    
    st.subheader("ğŸ“š ê¸ˆìœµ ìš©ì–´ ì‚¬ì „")
    st.write(f"ë“±ë¡ëœ ìš©ì–´: {len(st.session_state.financial_terms)}ê°œ")
    
    with st.expander("ìš©ì–´ ëª©ë¡ ë³´ê¸°"):
        for term in st.session_state.financial_terms.keys():
            st.write(f"â€¢ {term}")
    
    st.markdown("---")
    st.info("""
    **ì‚¬ìš© ë°©ë²•:**
    1. ìµœì‹  ë‰´ìŠ¤ ëª©ë¡ì—ì„œ ê´€ì‹¬ìˆëŠ” ê¸°ì‚¬ë¥¼ ì„ íƒí•˜ì„¸ìš”
    2. ê¸°ì‚¬ ë‚´ ë…¸ë€ìƒ‰ ìš©ì–´ë¥¼ í´ë¦­í•˜ê±°ë‚˜ ì±—ë´‡ì— ì§ˆë¬¸í•˜ì„¸ìš”
    3. RAG ê¸°ë°˜ìœ¼ë¡œ ì‰¬ìš´ ì„¤ëª…ì„ ë°›ì•„ë³´ì„¸ìš”
    """)
    
    st.markdown("---")
    st.caption("ğŸ’¡ OpenAI GPT-4o-mini ì‚¬ìš©")


# =========================================================
# ğŸ“¦ ë¡œê·¸ ë¡œë” + ë·°ì–´ (MVP) â€” CSVë¥¼ ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬/ìš”ì•½
# =========================================================
import pandas as pd

def load_logs_as_df(log_file: str) -> pd.DataFrame:
    """CSV(events.csv)ë¥¼ DataFrameìœ¼ë¡œ ë¡œë“œí•˜ê³  payload_jsonì„ í¼ì¹œë‹¤."""
    if not os.path.exists(log_file):
        st.info("ì•„ì§ ë¡œê·¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. (logs/events.csv)")
        return pd.DataFrame()

    # 1) CSV ë¡œë“œ + ì‹œê°„ íŒŒì‹±
    df = pd.read_csv(log_file)
    # ê²°ì¸¡ ëŒ€ë¹„(ëˆ„ë½ëœ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ë¹ˆ ì»¬ëŸ¼ ì¶”ê°€)
    base_cols = ["event_time","event_name","user_id","session_id","news_id","term","source","surface","message","payload_json"]
    for col in base_cols:
        if col not in df.columns:
            df[col] = ""

    df["event_time"] = pd.to_datetime(df["event_time"], errors="coerce", utc=True)

    # 2) payload_json íŒŒì‹±/í¼ì¹˜ê¸°
    def _safe_json_loads(x):
        try:
            return json.loads(x) if isinstance(x, str) and x.strip() else {}
        except Exception:
            return {}
    payloads = df["payload_json"].apply(_safe_json_loads)
    payload_df = pd.json_normalize(payloads)

    # ì¤‘ë³µ ì»¬ëŸ¼ëª… ì¶©ëŒ ë°©ì§€
    for c in list(payload_df.columns):
        new_c, i = c, 1
        while new_c in df.columns:
            i += 1
            new_c = f"{c}__{i}"
        if new_c != c:
            payload_df = payload_df.rename(columns={c: new_c})

    df = pd.concat([df.drop(columns=["payload_json"]), payload_df], axis=1)

    # 3) ë³´ê¸° ì¢‹ì€ ì •ë ¬
    order_cols = ["event_time","event_name","user_id","session_id","surface","source","news_id","term","message"]
    other_cols = [c for c in df.columns if c not in order_cols]
    df = df[order_cols + other_cols]
    df = df.sort_values("event_time").reset_index(drop=True)
    return df


def show_log_viewer():
    st.markdown("## ğŸ§ª ë¡œê·¸ ë·°ì–´ (MVP)")
    df = load_logs_as_df(LOG_FILE)
    if df.empty:
        return

    # ===== ìƒë‹¨ ìš”ì•½ (ì„¸ì…˜ ê¸°ì¤€ ê¸°ë³¸ ë·°) =====
    colA, colB, colC, colD = st.columns(4)
    with colA:
        st.metric("ì´ ì´ë²¤íŠ¸", f"{len(df):,}")
    with colB:
        st.metric("ì„¸ì…˜ ìˆ˜", df["session_id"].nunique())
    with colC:
        st.metric("ìœ ì € ìˆ˜", df["user_id"].nunique())
    with colD:
        st.metric("ì´ë²¤íŠ¸ ì¢…ë¥˜", df["event_name"].nunique())

    # ===== [ì¶”ê°€] ìœ ì € ê¸°ì¤€ ìš”ì•½ ìŠ¤ìœ„ì¹˜ & ìš”ì•½ ì¹´ë“œ =====
    st.markdown("---")
    agg_by_user = st.toggle(
        "ğŸ‘¤ ìœ ì €(user_id) ê¸°ì¤€ìœ¼ë¡œ ìš”ì•½ ë³´ê¸°",
        value=False,
        help="ì„¸ì…˜ì´ ì—¬ëŸ¬ ê°œì—¬ë„ ê°™ì€ ìœ ì €ë¡œ ë¬¶ì–´ì„œ ë´…ë‹ˆë‹¤."
    )

    if agg_by_user:
        # ìœ ì € ë‹¨ìœ„ ì§‘ê³„
        g = (
            df.groupby("user_id", dropna=False)
              .agg(
                  events=("event_name", "count"),
                  sessions=("session_id", "nunique"),
                  first_seen=("event_time", "min"),
                  last_seen=("event_time", "max")
              )
              .reset_index()
              .sort_values(["events","sessions"], ascending=False)
        )

        # ìœ ì € ê¸°ì¤€ ë©”íŠ¸ë¦­
        colU1, colU2, colU3, colU4 = st.columns(4)
        with colU1:
            st.metric("ê³ ìœ  ìœ ì € ìˆ˜", f"{len(g):,}")
        with colU2:
            st.metric("ìœ ì €ë‹¹ í‰ê·  ì„¸ì…˜", f"{(g['sessions'].mean() if len(g) else 0):.2f}")
        with colU3:
            st.metric("ìœ ì €ë‹¹ í‰ê·  ì´ë²¤íŠ¸", f"{(g['events'].mean() if len(g) else 0):.1f}")
        with colU4:
            st.metric("ì´ ì´ë²¤íŠ¸(ìœ ì € í•©ê³„)", f"{int(g['events'].sum()):,}")

        # ìƒìœ„ ìœ ì € í‘œ
        st.caption("ìœ ì €ë³„ í™œë™ ìš”ì•½ (ì´ë²¤íŠ¸/ì„¸ì…˜ ë§ì€ ìˆœ)")
        st.dataframe(g.head(50), use_container_width=True, height=320)

        # íŠ¹ì • ìœ ì € íƒ€ì„ë¼ì¸
        st.markdown("### ğŸ” íŠ¹ì • ìœ ì € íƒ€ì„ë¼ì¸")
        target_user = st.selectbox("ìœ ì € ì„ íƒ", options=g["user_id"].tolist() if len(g) else [])
        if target_user:
            udf = df[df["user_id"] == target_user].copy().sort_values("event_time")

            st.write(f"ì„¸ì…˜ ìˆ˜: {udf['session_id'].nunique()}ê°œ")
            sess_sum = (
                udf.groupby("session_id", dropna=False)
                   .agg(
                       events=("event_name","count"),
                       start=("event_time","min"),
                       end=("event_time","max")
                   )
                   .assign(dwell_sec=lambda x: (x["end"] - x["start"]).dt.total_seconds())
                   .sort_values("start", ascending=False)
            )
            st.dataframe(sess_sum, use_container_width=True, height=260)

            sel_sess = st.selectbox("ì„¸ì…˜ ì„ íƒ", options=sess_sum.index.tolist() if len(sess_sum) else [])
            if sel_sess:
                sdf = udf[udf["session_id"] == sel_sess].copy()
                sdf["next_time"] = sdf["event_time"].shift(-1)
                sdf["gap_sec"] = (sdf["next_time"] - sdf["event_time"]).dt.total_seconds()
                st.dataframe(
                    sdf[["event_time","event_name","surface","source","news_id","term","message","gap_sec"]],
                    use_container_width=True, height=320
                )

        # ìœ ì € ê¸°ì¤€ ë³´ê¸°ì—ì„œëŠ” ê¸°ë³¸ íƒ­ ìˆ¨ê¹€
        return

    # ===== ê¸°ë³¸ íƒ­: ì „ì²´í‘œ / ì´ë²¤íŠ¸ìš”ì•½ / ì„¸ì…˜íƒ€ì„ë¼ì¸ / ìš©ì–´í†µê³„ =====
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“„ ì „ì²´ ë¡œê·¸", "ğŸ“Š ì´ë²¤íŠ¸ ìš”ì•½", "ğŸ§µ ì„¸ì…˜ íƒ€ì„ë¼ì¸", "ğŸ·ï¸ ìš©ì–´ í†µê³„"])

    with tab1:
        st.caption("CSVë¥¼ í…Œì´ë¸”ë¡œ ë³´ê¸°")
        st.dataframe(df, use_container_width=True, height=420)

    with tab2:
        st.caption("ì´ë²¤íŠ¸ë³„ ê±´ìˆ˜/ìµœê·¼ 10ê±´")
        counts = df["event_name"].value_counts().rename_axis("event_name").reset_index(name="count")
        st.dataframe(counts, use_container_width=True, height=250)
        try:
            st.bar_chart(data=counts.set_index("event_name"))
        except Exception:
            pass

        nc = (df["event_name"] == "news_click").sum()
        ndo = (df["event_name"] == "news_detail_open").sum()
        conv = (ndo / nc * 100) if nc else 0
        st.write(f"**í´ë¦­â†’ì§„ì… ì „í™˜ìœ¨(rough)**: {conv:.1f}%  (clicks={nc}, opens={ndo})")

    with tab3:
        st.caption("ì„¸ì…˜ì„ ì„ íƒí•´ íƒ€ì„ë¼ì¸ í™•ì¸")
        session_ids = df["session_id"].dropna().unique().tolist()
        sess = st.selectbox("ì„¸ì…˜ ì„ íƒ", options=session_ids, index=0 if session_ids else None)
        if sess:
            sdf = df[df["session_id"] == sess].copy().sort_values("event_time")
            sdf["next_time"] = sdf["event_time"].shift(-1)
            sdf["gap_sec"] = (sdf["next_time"] - sdf["event_time"]).dt.total_seconds()
            st.dataframe(
                sdf[["event_time","event_name","surface","source","news_id","term","message","gap_sec"]],
                use_container_width=True, height=420
            )

    with tab4:
        st.caption("ìš©ì–´ í´ë¦­/ì‘ë‹µ ê¸¸ì´ í†µê³„")
        gclick = df[df["event_name"] == "glossary_click"]
        gans = df[df["event_name"] == "glossary_answer"]

        col1, col2 = st.columns(2)
        with col1:
            st.write("ìš©ì–´ í´ë¦­ Top N")
            top_terms = gclick["term"].value_counts().head(10).rename_axis("term").reset_index(name="clicks")
            st.dataframe(top_terms, use_container_width=True, height=300)

        with col2:
            if "answer_len" in gans.columns:
                tmp = gans.copy()
                tmp["answer_len"] = pd.to_numeric(tmp["answer_len"], errors="coerce")
                agg = (
                    tmp.groupby("term", dropna=True)["answer_len"]
                       .agg(["count","mean","max"])
                       .sort_values("count", ascending=False)
                       .head(10)
                )
                st.write("ì‘ë‹µ ê¸¸ì´ ìš”ì•½(Top10)")
                st.dataframe(agg, use_container_width=True, height=300)
            else:
                st.info("`glossary_answer`ì— answer_lenì´ ì•„ì§ ì—†ì–´ìš”.")

# ğŸ‘‡ ì›í•˜ëŠ” ìœ„ì¹˜ì—ì„œ í˜¸ì¶œ (ì˜ˆ: í˜ì´ì§€ ë§¨ ì•„ë˜)
st.markdown("---")
show_log_viewer()
