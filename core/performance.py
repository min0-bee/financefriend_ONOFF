"""
ì„±ëŠ¥ ì¸¡ì • ë° ë¶„ì„ ìœ í‹¸ë¦¬í‹°
- ê° ë‹¨ê³„ë³„ ì‹œê°„ ì¸¡ì •
- ì„±ëŠ¥ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
- ê°œì„  ì „/í›„ ë¹„êµ
"""

import time
import streamlit as st
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from contextlib import contextmanager


@dataclass
class PerformanceStep:
    """ì„±ëŠ¥ ì¸¡ì • ë‹¨ê³„"""
    name: str
    start_time: float
    end_time: Optional[float] = None
    duration_ms: Optional[float] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def finish(self, metadata: Optional[Dict[str, Any]] = None):
        """ë‹¨ê³„ ì¢…ë£Œ ë° ì‹œê°„ ê³„ì‚°"""
        self.end_time = time.perf_counter()
        self.duration_ms = (self.end_time - self.start_time) * 1000
        if metadata:
            self.metadata.update(metadata)


@dataclass
class PerformanceProfile:
    """ì „ì²´ ì„±ëŠ¥ í”„ë¡œíŒŒì¼"""
    session_id: str
    user_input: str
    steps: List[PerformanceStep] = field(default_factory=list)
    total_duration_ms: Optional[float] = None
    optimization_enabled: bool = False
    
    def add_step(self, name: str, metadata: Optional[Dict[str, Any]] = None) -> PerformanceStep:
        """ìƒˆ ë‹¨ê³„ ì¶”ê°€"""
        step = PerformanceStep(name=name, start_time=time.perf_counter(), metadata=metadata or {})
        self.steps.append(step)
        return step
    
    def finish(self):
        """í”„ë¡œíŒŒì¼ ì™„ë£Œ"""
        if self.steps:
            first_step = self.steps[0]
            last_step = self.steps[-1]
            if last_step.end_time:
                self.total_duration_ms = (last_step.end_time - first_step.start_time) * 1000
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "session_id": self.session_id,
            "user_input": self.user_input,
            "optimization_enabled": self.optimization_enabled,
            "total_duration_ms": self.total_duration_ms,
            "steps": [
                {
                    "name": step.name,
                    "duration_ms": step.duration_ms,
                    "metadata": step.metadata
                }
                for step in self.steps
                if step.duration_ms is not None
            ]
        }
    
    def get_summary(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ì •ë³´"""
        finished_steps = [s for s in self.steps if s.duration_ms is not None]
        if not finished_steps:
            return {}
        
        return {
            "total_ms": self.total_duration_ms,
            "step_count": len(finished_steps),
            "steps": {
                step.name: {
                    "duration_ms": round(step.duration_ms, 2),
                    "percentage": round((step.duration_ms / self.total_duration_ms * 100) if self.total_duration_ms else 0, 2)
                }
                for step in finished_steps
            },
            "bottleneck": max(finished_steps, key=lambda s: s.duration_ms).name if finished_steps else None
        }


class PerformanceTracker:
    """ì„±ëŠ¥ ì¶”ì ê¸° (ì‹±ê¸€í†¤ íŒ¨í„´)"""
    
    def __init__(self):
        self.profiles: List[PerformanceProfile] = []
        self.current_profile: Optional[PerformanceProfile] = None
    
    def start_profile(self, user_input: str, optimization_enabled: bool = False) -> PerformanceProfile:
        """ìƒˆ ì„±ëŠ¥ í”„ë¡œíŒŒì¼ ì‹œì‘"""
        session_id = st.session_state.get("session_id", "unknown")
        profile = PerformanceProfile(
            session_id=session_id,
            user_input=user_input,
            optimization_enabled=optimization_enabled
        )
        self.current_profile = profile
        return profile
    
    def finish_current_profile(self):
        """í˜„ì¬ í”„ë¡œíŒŒì¼ ì™„ë£Œ"""
        if self.current_profile:
            self.current_profile.finish()
            self.profiles.append(self.current_profile)
            # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
            if len(self.profiles) > 100:
                self.profiles = self.profiles[-100:]
            self.current_profile = None
    
    def get_current_profile(self) -> Optional[PerformanceProfile]:
        """í˜„ì¬ í”„ë¡œíŒŒì¼ ë°˜í™˜"""
        return self.current_profile
    
    @contextmanager
    def measure_step(self, name: str, metadata: Optional[Dict[str, Any]] = None):
        """ë‹¨ê³„ ì¸¡ì • ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        if not self.current_profile:
            raise ValueError("í”„ë¡œíŒŒì¼ì´ ì‹œì‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. start_profile()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        step = self.current_profile.add_step(name, metadata)
        try:
            yield step
        finally:
            step.finish()
    
    def get_comparison_report(self) -> Dict[str, Any]:
        """ê°œì„  ì „/í›„ ë¹„êµ ë¦¬í¬íŠ¸"""
        optimized = [p for p in self.profiles if p.optimization_enabled]
        non_optimized = [p for p in self.profiles if not p.optimization_enabled]
        
        if not optimized or not non_optimized:
            return {"error": "ë¹„êµí•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì í™” ì „/í›„ ë°ì´í„°ê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤."}
        
        # í‰ê·  ì‹œê°„ ê³„ì‚°
        avg_optimized = sum(p.total_duration_ms for p in optimized if p.total_duration_ms) / len(optimized)
        avg_non_optimized = sum(p.total_duration_ms for p in non_optimized if p.total_duration_ms) / len(non_optimized)
        
        # ë‹¨ê³„ë³„ í‰ê·  ì‹œê°„
        step_avg_optimized = {}
        step_avg_non_optimized = {}
        
        for profile in optimized:
            for step in profile.steps:
                if step.duration_ms:
                    if step.name not in step_avg_optimized:
                        step_avg_optimized[step.name] = []
                    step_avg_optimized[step.name].append(step.duration_ms)
        
        for profile in non_optimized:
            for step in profile.steps:
                if step.duration_ms:
                    if step.name not in step_avg_non_optimized:
                        step_avg_non_optimized[step.name] = []
                    step_avg_non_optimized[step.name].append(step.duration_ms)
        
        # í‰ê·  ê³„ì‚°
        step_avg_optimized = {k: sum(v)/len(v) for k, v in step_avg_optimized.items()}
        step_avg_non_optimized = {k: sum(v)/len(v) for k, v in step_avg_non_optimized.items()}
        
        improvement = ((avg_non_optimized - avg_optimized) / avg_non_optimized * 100) if avg_non_optimized > 0 else 0
        
        return {
            "total": {
                "before_ms": round(avg_non_optimized, 2),
                "after_ms": round(avg_optimized, 2),
                "improvement_percent": round(improvement, 2),
                "improvement_ms": round(avg_non_optimized - avg_optimized, 2)
            },
            "steps": {
                step_name: {
                    "before_ms": round(step_avg_non_optimized.get(step_name, 0), 2),
                    "after_ms": round(step_avg_optimized.get(step_name, 0), 2),
                    "improvement_ms": round(step_avg_non_optimized.get(step_name, 0) - step_avg_optimized.get(step_name, 0), 2),
                    "improvement_percent": round(
                        ((step_avg_non_optimized.get(step_name, 0) - step_avg_optimized.get(step_name, 0)) / 
                         step_avg_non_optimized.get(step_name, 1) * 100) if step_avg_non_optimized.get(step_name, 0) > 0 else 0, 
                        2
                    )
                }
                for step_name in set(list(step_avg_optimized.keys()) + list(step_avg_non_optimized.keys()))
            },
            "sample_count": {
                "optimized": len(optimized),
                "non_optimized": len(non_optimized)
            }
        }


# ì „ì—­ ì„±ëŠ¥ ì¶”ì ê¸° ì¸ìŠ¤í„´ìŠ¤
_performance_tracker = None

def get_performance_tracker() -> PerformanceTracker:
    """ì„±ëŠ¥ ì¶”ì ê¸° ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _performance_tracker
    if _performance_tracker is None:
        _performance_tracker = PerformanceTracker()
    return _performance_tracker


def render_performance_report():
    """ì„±ëŠ¥ ë¦¬í¬íŠ¸ UI ë Œë”ë§"""
    tracker = get_performance_tracker()
    
    st.markdown("### ğŸ“Š ì„±ëŠ¥ ë¶„ì„ ë¦¬í¬íŠ¸")
    
    if not tracker.profiles:
        st.info("ì•„ì§ ì¸¡ì •ëœ ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì±—ë´‡ì— ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”!")
        return
    
    # ìµœê·¼ í”„ë¡œíŒŒì¼ í‘œì‹œ
    if tracker.profiles:
        latest = tracker.profiles[-1]
        st.markdown("#### ìµœê·¼ ì‘ë‹µ ì„±ëŠ¥")
        
        if latest.total_duration_ms:
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì´ ì‘ë‹µ ì‹œê°„", f"{latest.total_duration_ms:.0f}ms")
            with col2:
                st.metric("ë‹¨ê³„ ìˆ˜", len([s for s in latest.steps if s.duration_ms]))
            with col3:
                bottleneck = latest.get_summary().get("bottleneck", "N/A")
                st.metric("ë³‘ëª© ì§€ì ", bottleneck)
            
            # ë‹¨ê³„ë³„ ì‹œê°„ ì°¨íŠ¸
            finished_steps = [s for s in latest.steps if s.duration_ms is not None]
            if finished_steps:
                import pandas as pd
                df = pd.DataFrame([
                    {
                        "ë‹¨ê³„": step.name,
                        "ì‹œê°„ (ms)": round(step.duration_ms, 2),
                        "ë¹„ìœ¨ (%)": round((step.duration_ms / latest.total_duration_ms * 100) if latest.total_duration_ms else 0, 2)
                    }
                    for step in finished_steps
                ])
                st.dataframe(df, use_container_width=True)
    
    # ê°œì„  ì „/í›„ ë¹„êµ
    comparison = tracker.get_comparison_report()
    if "error" not in comparison:
        st.markdown("#### ê°œì„  ì „/í›„ ë¹„êµ")
        
        total = comparison.get("total", {})
        if total:
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ê°œì„  ì „", f"{total.get('before_ms', 0):.0f}ms")
            with col2:
                st.metric("ê°œì„  í›„", f"{total.get('after_ms', 0):.0f}ms")
            with col3:
                st.metric("ê°œì„ ìœ¨", f"{total.get('improvement_percent', 0):.1f}%", 
                         delta=f"-{total.get('improvement_ms', 0):.0f}ms")
            with col4:
                st.metric("ìƒ˜í”Œ ìˆ˜", 
                         f"ì „: {comparison.get('sample_count', {}).get('non_optimized', 0)}\n"
                         f"í›„: {comparison.get('sample_count', {}).get('optimized', 0)}")
        
        # ë‹¨ê³„ë³„ ë¹„êµ
        steps = comparison.get("steps", {})
        if steps:
            st.markdown("##### ë‹¨ê³„ë³„ ìƒì„¸ ë¹„êµ")
            import pandas as pd
            step_df = pd.DataFrame([
                {
                    "ë‹¨ê³„": step_name,
                    "ê°œì„  ì „ (ms)": data.get("before_ms", 0),
                    "ê°œì„  í›„ (ms)": data.get("after_ms", 0),
                    "ê°œì„  (ms)": data.get("improvement_ms", 0),
                    "ê°œì„ ìœ¨ (%)": data.get("improvement_percent", 0)
                }
                for step_name, data in steps.items()
            ])
            st.dataframe(step_df, use_container_width=True)

