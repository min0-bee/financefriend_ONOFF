import os
import csv
import json
import pandas as pd
from datetime import datetime, timezone
from core.config import LOG_DIR, LOG_FILE
from openai import OpenAI

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ•“ (1) í˜„ì¬ UTC ì‹œê°ì„ ISO í˜•ì‹ ë¬¸ìì—´ë¡œ ë°˜í™˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def now_utc_iso() -> str:
    """
    ğŸŒ í˜„ì¬ ì‹œê°ì„ UTC ê¸°ì¤€ìœ¼ë¡œ ISO 8601 ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì˜ˆ: "2025-10-22T08:30:25.123456+00:00"
    """
    return datetime.now(timezone.utc).isoformat()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“ (2) ë¡œê·¸ íŒŒì¼(events.csv) ì¡´ì¬ í™•ì¸ ë° ìƒì„±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ensure_log_file():
    """
    ğŸ“‹ logs/events.csv íŒŒì¼ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    - ë””ë ‰í† ë¦¬(LOG_DIR)ê°€ ì—†ìœ¼ë©´ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.
    - í—¤ë”(ì»¬ëŸ¼ëª…)ëŠ” ê³ ì •ëœ í‘œì¤€ ìŠ¤í‚¤ë§ˆë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    os.makedirs(LOG_DIR, exist_ok=True)  # logs í´ë” ì—†ìœ¼ë©´ ìƒì„±

    if not os.path.exists(LOG_FILE):
        with open(LOG_FILE, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(
                f,
                fieldnames=[
                    "event_time",   # ì´ë²¤íŠ¸ ë°œìƒ ì‹œê° (UTC)
                    "event_name",   # ì´ë²¤íŠ¸ ì¢…ë¥˜ (ì˜ˆ: news_click)
                    "user_id",      # ìœ ì € ì‹ë³„ì
                    "session_id",   # ì„¸ì…˜ ì‹ë³„ì
                    "news_id",      # ë‰´ìŠ¤ ID (í•´ë‹¹ ì‹œì—ë§Œ ê¸°ë¡)
                    "term",         # ê¸ˆìœµ ìš©ì–´ (í•´ë‹¹ ì‹œì—ë§Œ ê¸°ë¡)
                    "source",       # ì´ë²¤íŠ¸ ë°œìƒ ìœ„ì¹˜ (list/chat ë“±)
                    "surface",      # í™”ë©´ ìœ„ì¹˜ (home/detail/sidebar ë“±)
                    "message",      # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë©”ì‹œì§€ (ì±—ë´‡ ë“±)
                    "payload_json", # ì¶”ê°€ ì •ë³´(JSONìœ¼ë¡œ ì§ë ¬í™”ëœ ë°ì´í„°)
                ],
            )
            writer.writeheader()  # CSV í—¤ë” ì¶”ê°€


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ§¾ (3) ë¡œê·¸ CSV íŒŒì¼ì„ DataFrameìœ¼ë¡œ ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_logs_as_df(log_file: str) -> pd.DataFrame:
    """
    ğŸ§® logs/events.csv â†’ pandas DataFrameìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.
    ì£¼ìš” ê¸°ëŠ¥:
      - payload_json ì»¬ëŸ¼ì„ JSONìœ¼ë¡œ í’€ì–´ì„œ ë³„ë„ ì»¬ëŸ¼ìœ¼ë¡œ í™•ì¥
      - event_timeì„ datetime íƒ€ì…ìœ¼ë¡œ ë³€í™˜
      - í‘œì¤€ ì»¬ëŸ¼ ìˆœì„œëŒ€ë¡œ ì •ë ¬ í›„ ë°˜í™˜
    """
    if not os.path.exists(log_file):
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ DataFrame ë°˜í™˜
        return pd.DataFrame()

    # 1ï¸âƒ£ CSV ì½ê¸°
    df = pd.read_csv(log_file)

    # 2ï¸âƒ£ í‘œì¤€ ì»¬ëŸ¼ ë³´ì¥ (ì—†ëŠ” ê²½ìš° ë¹ˆ ì»¬ëŸ¼ìœ¼ë¡œ ì±„ì›€)
    base_cols = [
        "event_time",
        "event_name",
        "user_id",
        "session_id",
        "news_id",
        "term",
        "source",
        "surface",
        "message",
        "payload_json",
    ]
    for col in base_cols:
        if col not in df.columns:
            df[col] = ""

    # 3ï¸âƒ£ event_time ë¬¸ìì—´ â†’ datetime ë³€í™˜ (UTC ê¸°ì¤€)
    df["event_time"] = pd.to_datetime(df["event_time"], errors="coerce", utc=True)

    # 4ï¸âƒ£ payload_json ì»¬ëŸ¼ì„ ì•ˆì „í•˜ê²Œ JSON â†’ dictë¡œ ë³€í™˜
    def _safe_json_loads(x):
        try:
            return json.loads(x) if isinstance(x, str) and x.strip() else {}
        except Exception:
            return {}

    payloads = df["payload_json"].apply(_safe_json_loads)

    # 5ï¸âƒ£ payload ë‚´ìš©ì„ ë³„ë„ì˜ ì»¬ëŸ¼ìœ¼ë¡œ í™•ì¥ (json_normalize)
    payload_df = pd.json_normalize(payloads)

    # 6ï¸âƒ£ ê¸°ì¡´ ì»¬ëŸ¼ê³¼ ì´ë¦„ì´ ê²¹ì¹˜ëŠ” ê²½ìš° ë’¤ì— "__2" ê°™ì€ ìˆ«ìë¥¼ ë¶™ì„
    for c in list(payload_df.columns):
        new_c, i = c, 1
        while new_c in df.columns:  # ì¶©ëŒ ë°©ì§€
            i += 1
            new_c = f"{c}__{i}"
        if new_c != c:
            payload_df = payload_df.rename(columns={c: new_c})

    # 7ï¸âƒ£ ì›ë³¸ dfì™€ payload_df í•©ì¹˜ê¸°
    df = pd.concat([df.drop(columns=["payload_json"]), payload_df], axis=1)

    # 8ï¸âƒ£ ì»¬ëŸ¼ ìˆœì„œ ì¬ì •ë ¬ (ë³´ê¸° ì‰½ê²Œ)
    order_cols = [
        "event_time",
        "event_name",
        "user_id",
        "session_id",
        "surface",
        "source",
        "news_id",
        "term",
        "message",
    ]
    other_cols = [c for c in df.columns if c not in order_cols]

    # ìµœì¢… DataFrame: í‘œì¤€ ì»¬ëŸ¼ + ë‚˜ë¨¸ì§€ payload í™•ì¥ ì»¬ëŸ¼
    df = df[order_cols + other_cols].sort_values("event_time").reset_index(drop=True)
    return df


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   (4)  --- OpenAI: í´ë¼ì´ì–¸íŠ¸ & í˜¸ì¶œ í—¬í¼ ---
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_openai_client = None

def get_openai_client(api_key: str = None):
    """
    OpenAI Python SDK v1.x í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ì‹±ê¸€í†¤)
    - í™˜ê²½ë³€ìˆ˜/Streamlit secretsì—ì„œ í‚¤ë¥¼ ì°¾ê³ , ì—†ìœ¼ë©´ None ë°˜í™˜
    """
    global _openai_client
    if _openai_client is not None:
        return _openai_client

    # 1) ìš°ì„ ìˆœìœ„: ì „ë‹¬ ì¸ì â†’ í™˜ê²½ë³€ìˆ˜ â†’ st.secrets
    key = api_key or os.getenv("OPENAI_API_KEY")
    try:
        import streamlit as st
        if not key and "OPENAI_API_KEY" in st.secrets:
            key = st.secrets["OPENAI_API_KEY"]
    except Exception:
        pass

    # 2) í‚¤ê°€ ì—†ìœ¼ë©´ ì—°ê²° ê±´ë„ˆë›°ê¸°
    if not key:
        return None

    # 3) ì •ìƒ ìƒì„±
    _openai_client = OpenAI(api_key=key)
    return _openai_client


def llm_chat(messages, model: str = None, temperature: float = 0.3, max_tokens: int = 512):
    """
    ğŸ’¬ ChatGPT (Chat Completions API) í˜¸ì¶œ í—¬í¼ í•¨ìˆ˜
    --------------------------------------------------
    âœ… ê¸°ëŠ¥:
        - OpenAIì˜ ChatCompletions APIë¥¼ í˜¸ì¶œí•´ LLM ì‘ë‹µì„ ë°›ì•„ì˜´.
        - messages í˜•ì‹ì˜ ëŒ€í™” ì´ë ¥ì„ ì…ë ¥ë°›ì•„ ëª¨ë¸ì˜ ë‹µë³€ì„ ë°˜í™˜í•¨.
          (Streamlit ë“±ì—ì„œ ì±—ë´‡ ê¸°ëŠ¥ êµ¬í˜„ ì‹œ ìì£¼ ì‚¬ìš©)

    âœ… ë§¤ê°œë³€ìˆ˜:
        messages : list[dict]
            [{"role": "system"|"user"|"assistant", "content": "..."}] í˜•ì‹ì˜ ë©”ì‹œì§€ ë°°ì—´
            ì˜ˆì‹œ:
                [
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "ì˜¤ëŠ˜ì˜ ê¸ˆìœµ ë‰´ìŠ¤ ìš”ì•½í•´ì¤˜"}
                ]
        model : str, optional
            ì‚¬ìš©í•  OpenAI ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’ì€ core.configì˜ DEFAULT_OPENAI_MODEL)
        temperature : float, optional
            ìƒì„± í…ìŠ¤íŠ¸ì˜ ì°½ì˜ì„± ì¡°ì ˆ (0~1, ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì„±â†‘, ë†’ì„ìˆ˜ë¡ ë‹¤ì–‘ì„±â†‘)
        max_tokens : int, optional
            ëª¨ë¸ì´ ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜ (ì‘ë‹µ ê¸¸ì´ ì œí•œ)

    âœ… ë°˜í™˜ê°’:
        str : ëª¨ë¸ì´ ìƒì„±í•œ í…ìŠ¤íŠ¸ ì‘ë‹µ (ë¬¸ìì—´)
    """

    # âœ… 1. ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°
    #   - ê¸°ë³¸ ëª¨ë¸ëª… (ì˜ˆ: "gpt-4o-mini")
    #   - OpenAI API í‚¤
    from core.config import DEFAULT_OPENAI_MODEL, OPENAI_API_KEY

    # âœ… 2. OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = get_openai_client(OPENAI_API_KEY)

    # âœ… 3. ëª¨ë¸ ì§€ì • (ì§ì ‘ ì „ë‹¬ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
    model = model or DEFAULT_OPENAI_MODEL

    # âœ… 4. ChatCompletions API í˜¸ì¶œ
    #   - messages: ëŒ€í™” ì´ë ¥
    #   - temperature: ì°½ì˜ì„± ì¡°ì ˆ
    #   - max_tokens: ì‘ë‹µ ê¸¸ì´ ì œí•œ
    resp = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens,
    )

    # âœ… 5. ì‘ë‹µì—ì„œ ëª¨ë¸ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    return resp.choices[0].message.content.strip()


# === LLM ì—°ê²° ì§„ë‹¨ íŒ¨ë„ ===
def render_llm_diagnostics():
    import os, importlib, sys
    import streamlit as st

    st.markdown("### ğŸ§ª LLM ì—°ê²° ì§„ë‹¨")
    problems = []

    # 1) openai íŒ¨í‚¤ì§€ ì œëŒ€ë¡œ import ë˜ëŠ”ì§€
    try:
        import openai  # íŒ¨í‚¤ì§€ ëª¨ë“ˆ (v1ì—ì„œë„ ëª¨ë“ˆëª…ì€ openai)
        st.write("âœ… `import openai` OK", getattr(openai, "__version__", "unknown"))
    except Exception as e:
        st.error(f"âŒ `import openai` ì‹¤íŒ¨: {e}")
        problems.append("openai import ì‹¤íŒ¨")

    # 2) í”„ë¡œì íŠ¸ì— openai.py / openai í´ë”ë¡œ **ì´ë¦„ì¶©ëŒ** ìˆëŠ”ì§€
    import glob, os
    here = os.path.abspath(os.getcwd())
    shadow = []
    for pattern in ["openai.py", "openai/__init__.py"]:
        for p in glob.glob(os.path.join(here, "**", pattern), recursive=True):
            shadow.append(p)
    if shadow:
        st.error("âŒ í”„ë¡œì íŠ¸ ì•ˆì— `openai` ì´ë¦„ ì¶©ëŒ ê°€ëŠ¥ì„±:", icon="ğŸš«")
        for p in shadow:
            st.code(p)
        problems.append("ë¡œì»¬ íŒŒì¼/í´ë” ì´ë¦„ì¶©ëŒ(openai)")
    else:
        st.write("âœ… í”„ë¡œì íŠ¸ ë‚´ ì´ë¦„ì¶©ëŒ ì—†ìŒ")

    # 3) config ê°’ í™•ì¸
    try:
        from core import config
        st.write("âœ… `from core import config` OK")
        st.write({
            "DEFAULT_OPENAI_MODEL": getattr(config, "DEFAULT_OPENAI_MODEL", None),
            "USE_OPENAI": getattr(config, "USE_OPENAI", None),
            "OPENAI_API_KEY in config (bool)": bool(getattr(config, "OPENAI_API_KEY", None)),
        })
    except Exception as e:
        st.error(f"âŒ config import ì‹¤íŒ¨: {e}")
        problems.append("config import ì‹¤íŒ¨")

    # 4) í™˜ê²½ë³€ìˆ˜ í™•ì¸ (í˜„ì¬ í”„ë¡œì„¸ìŠ¤)
    st.write({
        "env.OPENAI_API_KEY": bool(os.getenv("OPENAI_API_KEY")),
    })

    # 5) .streamlit/secrets.toml ì½íˆëŠ”ì§€
    try:
        import streamlit as st
        st.write({
            "secrets.has_OPENAI_API_KEY": ("OPENAI_API_KEY" in st.secrets),
            "secrets.has_OPENAI_MODEL": ("OPENAI_MODEL" in st.secrets),
        })
    except Exception as e:
        st.warning(f"secrets ì ‘ê·¼ ê²½ê³ : {e}")

    # 6) OpenAI v1 í´ë¼ì´ì–¸íŠ¸ ìƒì„± & ê°„ì´ í˜¸ì¶œ
    try:
        from openai import OpenAI
        api_key = getattr(config, "OPENAI_API_KEY", None) or os.getenv("OPENAI_API_KEY")
        if not api_key:
            st.error("âŒ API í‚¤ ì—†ìŒ: config.OPENAI_API_KEY ë˜ëŠ” env.OPENAI_API_KEYê°€ ë¹„ì–´ìˆìŒ")
            problems.append("API í‚¤ ì—†ìŒ")
        else:
            client = OpenAI(api_key=api_key)
            st.write("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± OK")
            # ëª¨ë¸ í•‘(ê°€ë²¼ìš´ í˜¸ì¶œ): ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ í˜¹ì€ ìµœì†Œ chat í˜¸ì¶œ ì‹œê·¸ë‹ˆì²˜ í™•ì¸
            try:
                # ê°€ì¥ ê°€ë²¼ìš´ í™•ì¸: ëª¨ë¸ ë¦¬ìŠ¤íŠ¸
                _ = client.models.list()
                st.write("âœ… `client.models.list()` OK")
            except Exception as e:
                st.warning(f"âš ï¸ models.list ê²½ê³ : {e}")
            # ì§§ì€ ì±„íŒ… í˜¸ì¶œ ì‹œë„ (ëª¨ë¸ëª…ì€ config ì‚¬ìš©)
            try:
                mdl = getattr(config, "DEFAULT_OPENAI_MODEL", "gpt-4o-mini")
                resp = client.chat.completions.create(
                    model=mdl,
                    messages=[{"role": "user", "content": "ping"}],
                    max_tokens=5,
                )
                txt = resp.choices[0].message.content.strip()
                st.success(f"âœ… chat.completions ì‘ë‹µ OK: {txt!r}")
            except Exception as e:
                st.error(f"âŒ chat.completions ì‹¤íŒ¨: {e}")
                problems.append("chat.completions ì‹¤íŒ¨")
    except Exception as e:
        st.error(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        problems.append("OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨")

    if problems:
        st.markdown("**ìš”ì•½ (ì˜ì‹¬ í¬ì¸íŠ¸)**: " + ", ".join(problems))
    else:
        st.success("ğŸ‰ ì§„ë‹¨ìƒ ë¬¸ì œ ì—†ìŒ")

# ğŸ‘‰ í˜¸ì¶œ ìœ„ì¹˜ ì˜ˆì‹œ
# with st.sidebar:
#     render_llm_diagnostics()
