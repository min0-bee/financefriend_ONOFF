import os
import csv
import json
import uuid
import re
import pandas as pd
import streamlit as st
from datetime import datetime, timezone
from core.config import LOG_DIR, LOG_FILE
from openai import OpenAI
from core.logger import CSV_HEADER

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ•“ (1) í˜„ì¬ UTC ì‹œê°ì„ ISO í˜•ì‹ ë¬¸ìì—´ë¡œ ë°˜í™˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def now_utc_iso() -> str:
    """
    ğŸŒ í˜„ì¬ ì‹œê°ì„ UTC ê¸°ì¤€ìœ¼ë¡œ ISO 8601 ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì˜ˆ: "2025-10-22T08:30:25.123456+00:00"
    """
    return datetime.now(timezone.utc).isoformat()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“ (2) ë¡œê·¸ íŒŒì¼(events.csv) ì¡´ì¬ í™•ì¸ ë° ìƒì„±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ensure_log_file():
    """
    ğŸ“‹ logs/events.csv íŒŒì¼ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    - ë””ë ‰í† ë¦¬(LOG_DIR)ê°€ ì—†ìœ¼ë©´ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.
    - í—¤ë”(ì»¬ëŸ¼ëª…)ëŠ” core.loggerì˜ CSV_HEADERë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    os.makedirs(LOG_DIR, exist_ok=True)

    if not os.path.exists(LOG_FILE):
        with open(LOG_FILE, "w", newline="", encoding="utf-8-sig") as f:
            writer = csv.DictWriter(f, fieldnames=CSV_HEADER)
            writer.writeheader()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ§¾ (3) ë¡œê·¸ CSV íŒŒì¼ì„ DataFrameìœ¼ë¡œ ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_logs_as_df(log_file: str) -> pd.DataFrame:
    """
    ğŸ§® logs/events.csv â†’ pandas DataFrameìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.
    ì£¼ìš” ê¸°ëŠ¥:
      - payloadë¥¼ JSON í™•ì¥í•˜ì§€ ì•Šê³  ë¬¸ìì—´ ê·¸ëŒ€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
      - event_timeì„ datetime íƒ€ì…ìœ¼ë¡œ ë³€í™˜
      - ëˆ„ë½ëœ ì»¬ëŸ¼ì€ ë¹ˆ ë¬¸ìì—´ë¡œ ì±„ì›ë‹ˆë‹¤.
    """
    if not os.path.exists(log_file):
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ DataFrame ë°˜í™˜
        return pd.DataFrame(columns=CSV_HEADER)

    # 1ï¸âƒ£ CSV ì½ê¸°
    df = pd.read_csv(
        log_file,
        dtype=str,
        engine="python",
        on_bad_lines="skip",
        encoding="utf-8-sig",
    )

    # 2ï¸âƒ£ í‘œì¤€ ì»¬ëŸ¼ ë³´ì¥ (ì—†ëŠ” ê²½ìš° ë¹ˆ ì»¬ëŸ¼ìœ¼ë¡œ ì±„ì›€)
    for col in CSV_HEADER:
        if col not in df.columns:
            df[col] = ""

    # 3ï¸âƒ£ event_time ë¬¸ìì—´ â†’ datetime ë³€í™˜ (UTC ê¸°ì¤€)
    df["event_time"] = pd.to_datetime(df["event_time"], errors="coerce", utc=True)

    # # 4ï¸âƒ£ payload_json ì»¬ëŸ¼ì„ ì•ˆì „í•˜ê²Œ JSON â†’ dictë¡œ ë³€í™˜
    # def _safe_json_loads(x):
    #     try:
    #         return json.loads(x) if isinstance(x, str) and x.strip() else {}
    #     except Exception:
    #         return {}

    # payloads = df["payload_json"].apply(_safe_json_loads)

    # 5ï¸âƒ£ payload ë‚´ìš©ì„ ë³„ë„ì˜ ì»¬ëŸ¼ìœ¼ë¡œ í™•ì¥ (json_normalize)
    # payload_df = pd.json_normalize(payloads)

    # 4ï¸âƒ£ ìˆ«ìí˜• ì»¬ëŸ¼ ìë™ ë³€í™˜
    for col in ["click_count", "answer_len", "latency_ms"]:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")


    # ì»¬ëŸ¼ ìˆœì„œ ì¬ì •ë ¬ (ë³´ê¸° ì‰½ê²Œ)
    order_cols = [
        "event_id",
        "event_time",
        "event_name",
        "user_id",
        "session_id",
        "surface",
        "source",
        "news_id",
        "term",
        "message",
        "note",
        "title",
        "click_count",
        "answer_len",
        "via",
        "latency_ms",
        "payload",  # âœ… ê·¸ëŒ€ë¡œ ìœ ì§€
    ]
    order_cols = [c for c in order_cols if c in df.columns]
    df = df[order_cols].sort_values("event_time").reset_index(drop=True)
    return df


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   (4)  --- OpenAI: í´ë¼ì´ì–¸íŠ¸ & í˜¸ì¶œ í—¬í¼ ---
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@st.cache_resource
def get_openai_client(api_key: str = None):
    """
    OpenAI Python SDK v1.x í´ë¼ì´ì–¸íŠ¸ ìƒì„± (st.cache_resourceë¡œ ìºì‹±)
    - í•œ ë²ˆ ìƒì„±ëœ í´ë¼ì´ì–¸íŠ¸ëŠ” ì„¸ì…˜ ê°„ ì¬ì‚¬ìš©
    - í™˜ê²½ë³€ìˆ˜/Streamlit secretsì—ì„œ í‚¤ë¥¼ ì°¾ê³ , ì—†ìœ¼ë©´ None ë°˜í™˜
    """
    # 1) ìš°ì„ ìˆœìœ„: ì „ë‹¬ ì¸ì â†’ í™˜ê²½ë³€ìˆ˜ â†’ st.secrets
    key = api_key or os.getenv("OPENAI_API_KEY")
    try:
        if not key and "OPENAI_API_KEY" in st.secrets:
            key = st.secrets["OPENAI_API_KEY"]
    except Exception:
        pass

    # 2) í‚¤ê°€ ì—†ìœ¼ë©´ ì—°ê²° ê±´ë„ˆë›°ê¸°
    if not key:
        return None

    # 3) ì •ìƒ ìƒì„±
    return OpenAI(api_key=key)


def llm_chat(messages, model: str = None, temperature: float = 0.3, max_tokens: int = 512, return_metadata: bool = False, stream: bool = False):
    """
    ğŸ’¬ ChatGPT (Chat Completions API) í˜¸ì¶œ í—¬í¼ í•¨ìˆ˜
    --------------------------------------------------
    âœ… ê¸°ëŠ¥:
        - OpenAIì˜ ChatCompletions APIë¥¼ í˜¸ì¶œí•´ LLM ì‘ë‹µì„ ë°›ì•„ì˜´.
        - messages í˜•ì‹ì˜ ëŒ€í™” ì´ë ¥ì„ ì…ë ¥ë°›ì•„ ëª¨ë¸ì˜ ë‹µë³€ì„ ë°˜í™˜í•¨.
          (Streamlit ë“±ì—ì„œ ì±—ë´‡ ê¸°ëŠ¥ êµ¬í˜„ ì‹œ ìì£¼ ì‚¬ìš©)

    âœ… ë§¤ê°œë³€ìˆ˜:
        messages : list[dict]
            [{"role": "system"|"user"|"assistant", "content": "..."}] í˜•ì‹ì˜ ë©”ì‹œì§€ ë°°ì—´
            ì˜ˆì‹œ:
                [
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "ì˜¤ëŠ˜ì˜ ê¸ˆìœµ ë‰´ìŠ¤ ìš”ì•½í•´ì¤˜"}
                ]
        model : str, optional
            ì‚¬ìš©í•  OpenAI ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’ì€ core.configì˜ DEFAULT_OPENAI_MODEL)
        temperature : float, optional
            ìƒì„± í…ìŠ¤íŠ¸ì˜ ì°½ì˜ì„± ì¡°ì ˆ (0~1, ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì„±â†‘, ë†’ì„ìˆ˜ë¡ ë‹¤ì–‘ì„±â†‘)
        max_tokens : int, optional
            ëª¨ë¸ì´ ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜ (ì‘ë‹µ ê¸¸ì´ ì œí•œ)
        return_metadata : bool, optional
            Trueë©´ ì‘ë‹µê³¼ í•¨ê»˜ ë©”íƒ€ë°ì´í„°(í† í° ì‚¬ìš©ëŸ‰, ëª¨ë¸ëª… ë“±)ë„ ë°˜í™˜
        stream : bool, optional
            Trueë©´ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ë°˜í™˜ (ì œë„ˆë ˆì´í„°)

    âœ… ë°˜í™˜ê°’:
        str ë˜ëŠ” tuple ë˜ëŠ” generator : 
            - stream=False, return_metadata=False: ëª¨ë¸ì´ ìƒì„±í•œ í…ìŠ¤íŠ¸ ì‘ë‹µ (ë¬¸ìì—´)
            - stream=False, return_metadata=True: (ì‘ë‹µ í…ìŠ¤íŠ¸, ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬)
            - stream=True: ì œë„ˆë ˆì´í„° (ê° ë¸íƒ€ë¥¼ yield)
              ë©”íƒ€ë°ì´í„° ì˜ˆì‹œ: {
                  "model": "gpt-4o-mini",
                  "tokens": {"input": 150, "output": 200, "total": 350},
                  "api_params": {"temperature": 0.3, "max_tokens": 512}
              }
    """

    try:
        # âœ… 1. ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°
        #   - ê¸°ë³¸ ëª¨ë¸ëª… (ì˜ˆ: "gpt-4o-mini")
        #   - OpenAI API í‚¤
        from core.config import DEFAULT_OPENAI_MODEL, OPENAI_API_KEY

    except Exception as e:
        st.error(f"âŒ config import ì‹¤íŒ¨: {e}")
        problems.append("config import ì‹¤íŒ¨")

    # âœ… 2. OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = get_openai_client(OPENAI_API_KEY)

    # âœ… 3. ëª¨ë¸ ì§€ì • (ì§ì ‘ ì „ë‹¬ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
    model = model or DEFAULT_OPENAI_MODEL

    # âœ… 4. ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì²˜ë¦¬
    if stream:
        def stream_generator():
            response_text = ""
            usage = None
            with client.chat.completions.stream(
                model=model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
            ) as stream_resp:
                for event in stream_resp:
                    if event.type == "message.delta":
                        delta = event.delta.content or ""
                        if delta:
                            response_text += delta
                            yield delta
                    elif event.type == "message.completed":
                        usage = event.response.usage  # type: ignore[attr-defined]
            
            # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ ë©”íƒ€ë°ì´í„° ë°˜í™˜ (return_metadata=Trueì¸ ê²½ìš°)
            if return_metadata:
                metadata = {
                    "model": model,
                    "tokens": {
                        "input": usage.prompt_tokens if usage else 0,
                        "output": usage.completion_tokens if usage else 0,
                        "total": usage.total_tokens if usage else 0
                    },
                    "api_params": {
                        "temperature": temperature,
                        "max_tokens": max_tokens
                    }
                }
                yield ("__METADATA__", metadata)
        
        return stream_generator()

    # âœ… 5. ì¼ë°˜ ëª¨ë“œ: ChatCompletions API í˜¸ì¶œ
    #   - messages: ëŒ€í™” ì´ë ¥
    #   - temperature: ì°½ì˜ì„± ì¡°ì ˆ
    #   - max_tokens: ì‘ë‹µ ê¸¸ì´ ì œí•œ
    resp = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens,
    )

    # âœ… 6. ì‘ë‹µì—ì„œ ëª¨ë¸ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    response_text = resp.choices[0].message.content.strip()
    
    # âœ… 7. ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ (ì—ì´ì „íŠ¸ ìˆ˜ì§‘ìš©)
    if return_metadata:
        usage = resp.usage
        metadata = {
            "model": model,
            "tokens": {
                "input": usage.prompt_tokens if usage else 0,
                "output": usage.completion_tokens if usage else 0,
                "total": usage.total_tokens if usage else 0
            },
            "api_params": {
                "temperature": temperature,
                "max_tokens": max_tokens
            }
        }
        return response_text, metadata
    
    return response_text


# === LLM ì—°ê²° ì§„ë‹¨ íŒ¨ë„ ===
def render_llm_diagnostics():
    import os, importlib, sys
    import streamlit as st

    st.markdown("### ğŸ§ª LLM ì—°ê²° ì§„ë‹¨")
    problems = []

    # 1) openai íŒ¨í‚¤ì§€ ì œëŒ€ë¡œ import ë˜ëŠ”ì§€
    try:
        import openai  # íŒ¨í‚¤ì§€ ëª¨ë“ˆ (v1ì—ì„œë„ ëª¨ë“ˆëª…ì€ openai)
        st.write("âœ… `import openai` OK", getattr(openai, "__version__", "unknown"))
    except Exception as e:
        st.error(f"âŒ `import openai` ì‹¤íŒ¨: {e}")
        problems.append("openai import ì‹¤íŒ¨")

    # 2) í”„ë¡œì íŠ¸ì— openai.py / openai í´ë”ë¡œ **ì´ë¦„ì¶©ëŒ** ìˆëŠ”ì§€
    import glob, os
    here = os.path.abspath(os.getcwd())
    shadow = []
    for pattern in ["openai.py", "openai/__init__.py"]:
        for p in glob.glob(os.path.join(here, "**", pattern), recursive=True):
            shadow.append(p)
    if shadow:
        st.error("âŒ í”„ë¡œì íŠ¸ ì•ˆì— `openai` ì´ë¦„ ì¶©ëŒ ê°€ëŠ¥ì„±:", icon="ğŸš«")
        for p in shadow:
            st.code(p)
        problems.append("ë¡œì»¬ íŒŒì¼/í´ë” ì´ë¦„ì¶©ëŒ(openai)")
    else:
        st.write("âœ… í”„ë¡œì íŠ¸ ë‚´ ì´ë¦„ì¶©ëŒ ì—†ìŒ")

    # 3) config ê°’ í™•ì¸
    try:
        from core import config
        st.write("âœ… `from core import config` OK")
        st.write({
            "DEFAULT_OPENAI_MODEL": getattr(config, "DEFAULT_OPENAI_MODEL", None),
            "USE_OPENAI": getattr(config, "USE_OPENAI", None),
            "OPENAI_API_KEY in config (bool)": bool(getattr(config, "OPENAI_API_KEY", None)),
        })
    except Exception as e:
        st.error(f"âŒ config import ì‹¤íŒ¨: {e}")
        problems.append("config import ì‹¤íŒ¨")

    # 4) í™˜ê²½ë³€ìˆ˜ í™•ì¸ (í˜„ì¬ í”„ë¡œì„¸ìŠ¤)
    st.write({
        "env.OPENAI_API_KEY": bool(os.getenv("OPENAI_API_KEY")),
    })

    # 5) .streamlit/secrets.toml ì½íˆëŠ”ì§€
    try:
        import streamlit as st
        st.write({
            "secrets.has_OPENAI_API_KEY": ("OPENAI_API_KEY" in st.secrets),
            "secrets.has_OPENAI_MODEL": ("OPENAI_MODEL" in st.secrets),
        })
    except Exception as e:
        st.warning(f"secrets ì ‘ê·¼ ê²½ê³ : {e}")

    # 6) OpenAI v1 í´ë¼ì´ì–¸íŠ¸ ìƒì„± & ê°„ì´ í˜¸ì¶œ
    try:
        from openai import OpenAI
        api_key = getattr(config, "OPENAI_API_KEY", None) or os.getenv("OPENAI_API_KEY")
        if not api_key:
            st.error("âŒ API í‚¤ ì—†ìŒ: config.OPENAI_API_KEY ë˜ëŠ” env.OPENAI_API_KEYê°€ ë¹„ì–´ìˆìŒ")
            problems.append("API í‚¤ ì—†ìŒ")
        else:
            client = OpenAI(api_key=api_key)
            st.write("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± OK")
            # ëª¨ë¸ í•‘(ê°€ë²¼ìš´ í˜¸ì¶œ): ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ í˜¹ì€ ìµœì†Œ chat í˜¸ì¶œ ì‹œê·¸ë‹ˆì²˜ í™•ì¸
            try:
                # ê°€ì¥ ê°€ë²¼ìš´ í™•ì¸: ëª¨ë¸ ë¦¬ìŠ¤íŠ¸
                _ = client.models.list()
                st.write("âœ… `client.models.list()` OK")
            except Exception as e:
                st.warning(f"âš ï¸ models.list ê²½ê³ : {e}")
            # ì§§ì€ ì±„íŒ… í˜¸ì¶œ ì‹œë„ (ëª¨ë¸ëª…ì€ config ì‚¬ìš©)
            try:
                mdl = getattr(config, "DEFAULT_OPENAI_MODEL", "gpt-4o-mini")
                resp = client.chat.completions.create(
                    model=mdl,
                    messages=[{"role": "user", "content": "ping"}],
                    max_tokens=5,
                )
                txt = resp.choices[0].message.content.strip()
                st.success(f"âœ… chat.completions ì‘ë‹µ OK: {txt!r}")
            except Exception as e:
                st.error(f"âŒ chat.completions ì‹¤íŒ¨: {e}")
                problems.append("chat.completions ì‹¤íŒ¨")
    except Exception as e:
        st.error(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        problems.append("OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨")

    if problems:
        st.markdown("**ìš”ì•½ (ì˜ì‹¬ í¬ì¸íŠ¸)**: " + ", ".join(problems))
    else:
        st.success("ğŸ‰ ì§„ë‹¨ìƒ ë¬¸ì œ ì—†ìŒ")

# ğŸ‘‰ í˜¸ì¶œ ìœ„ì¹˜ ì˜ˆì‹œ
# with st.sidebar:
#     render_llm_diagnostics()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ”— (5) URL ê°ì§€ ë° ì¶”ì¶œ ìœ í‹¸ë¦¬í‹°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_urls_from_text(text: str) -> list[str]:
    """
    í…ìŠ¤íŠ¸ì—ì„œ URLì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        text: URLì´ í¬í•¨ë  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸
        
    Returns:
        ë°œê²¬ëœ URL ë¦¬ìŠ¤íŠ¸
    """
    if not text:
        return []
    
    # URL íŒ¨í„´ (http/httpsë¡œ ì‹œì‘í•˜ëŠ” URL)
    url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+[^\s<>"{}|\\^`\[\].,;!?]'
    urls = re.findall(url_pattern, text)
    
    return urls


def is_url(text: str) -> bool:
    """
    í…ìŠ¤íŠ¸ê°€ URLì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    
    Args:
        text: í™•ì¸í•  í…ìŠ¤íŠ¸
        
    Returns:
        URLì´ë©´ True, ì•„ë‹ˆë©´ False
    """
    if not text or not text.strip():
        return False
    
    text = text.strip()
    urls = extract_urls_from_text(text)
    
    # í…ìŠ¤íŠ¸ ì „ì²´ê°€ URLì¸ì§€ í™•ì¸ (ì•ë’¤ ê³µë°± ì œê±° í›„ ë¹„êµ)
    return len(urls) == 1 and text.strip() == urls[0]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“° (6) ê¸°ì‚¬ ì°¾ê¸° ìš”ì²­ ê°ì§€ ë° í‚¤ì›Œë“œ ì¶”ì¶œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def detect_article_search_request(text: str) -> tuple[bool, str]:
    """
    ì‚¬ìš©ì ì…ë ¥ì´ ê¸°ì‚¬ ì°¾ê¸° ìš”ì²­ì¸ì§€ ê°ì§€í•˜ê³  í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        text: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        
    Returns:
        (is_request, keyword) íŠœí”Œ
        - is_request: ê¸°ì‚¬ ì°¾ê¸° ìš”ì²­ì´ë©´ True
        - keyword: ì¶”ì¶œëœ í‚¤ì›Œë“œ (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)
    """
    if not text or not text.strip():
        return False, ""
    
    text = text.strip()
    
    # ê¸°ì‚¬ ì°¾ê¸° íŒ¨í„´ë“¤ (í™•ì¥)
    search_patterns = [
        # "~ì— ëŒ€í•´ ê¸°ì‚¬ ë³´ì—¬ì¤˜" íŒ¨í„´
        r'(.+?)(?:ì—\s*ëŒ€í•´|ì—\s*ê´€í•´|ì—\s*ëŒ€í•œ|ì—\s*ê´€í•œ).*?ê¸°ì‚¬.*?(?:ë³´ì—¬|ì°¾ì•„|ì•Œë ¤|ì•Œê³ ì‹¶|ë³´ê³ ì‹¶)',
        r'(.+?)(?:ì—\s*ëŒ€í•´|ì—\s*ê´€í•´|ì—\s*ëŒ€í•œ|ì—\s*ê´€í•œ).*?(?:ê¸°ì‚¬|ë‰´ìŠ¤|ê¸°ì‚¬.*?ë³´ì—¬|ë‰´ìŠ¤.*?ë³´ì—¬)',
        r'(.+?)(?:ê¸°ì‚¬|ë‰´ìŠ¤).*?(?:ë³´ì—¬|ì°¾ì•„|ì•Œë ¤|ë³´ê³ ì‹¶|ì•Œê³ ì‹¶)',
        r'(.+?)(?:ì—\s*ëŒ€í•´|ì—\s*ê´€í•´).*?(?:ë”\s*ì•Œê³ ì‹¶|ë”\s*ë³´ê³ ì‹¶|ë”\s*ì•Œë ¤)',
        r'(.+?)(?:ì—\s*ëŒ€í•œ|ì—\s*ê´€í•œ).*?(?:ê¸°ì‚¬|ë‰´ìŠ¤)',
        # "~ì— ëŒ€í•´ ì•Œê³ ì‹¶ì–´" íŒ¨í„´ (ê¸°ì‚¬/ë‰´ìŠ¤ ì—†ì´ë„ ë§¤ì¹­)
        r'(.+?)(?:ì—\s*ëŒ€í•´|ì—\s*ê´€í•´).*?ì•Œê³ ì‹¶',
        r'(.+?)(?:ì—\s*ëŒ€í•´|ì—\s*ê´€í•´).*?ë³´ê³ ì‹¶',
        # "~ê°€ ë” í•„ìš”í•´", "~ê´€ë ¨ ë‰´ìŠ¤" íŒ¨í„´ ì¶”ê°€
        r'(.+?)(?:ì—?\s*ê´€ë ¨|ì—?\s*ê´€í•œ|ì—?\s*ëŒ€í•œ).*?(?:ë‰´ìŠ¤|ê¸°ì‚¬).*?(?:ë”\s*í•„ìš”|ë”\s*ë³´ê³ ì‹¶|ë”\s*ì•Œê³ ì‹¶|ê°€ì ¸ì™€|ì°¾ì•„)',
        r'(.+?)(?:ì—?\s*ê´€ë ¨|ì—?\s*ê´€í•œ|ì—?\s*ëŒ€í•œ).*?(?:ë‰´ìŠ¤|ê¸°ì‚¬).*?í•„ìš”',
        r'(.+?)(?:ì—?\s*ê´€ë ¨|ì—?\s*ê´€í•œ|ì—?\s*ëŒ€í•œ).*?ë‰´ìŠ¤',
        r'(.+?)(?:ì—?\s*ê´€ë ¨|ì—?\s*ê´€í•œ|ì—?\s*ëŒ€í•œ).*?ê¸°ì‚¬',
        r'(.+?)(?:ê°€|ì´|ì„|ë¥¼).*?(?:ë”\s*í•„ìš”|ë”\s*ë³´ê³ ì‹¶|ë”\s*ì•Œê³ ì‹¶)',
        r'(.+?)(?:ì—?\s*ëŒ€í•´|ì—?\s*ê´€í•´).*?(?:ë‰´ìŠ¤|ê¸°ì‚¬).*?(?:ë”\s*í•„ìš”|ë”\s*ë³´ê³ ì‹¶|ë”\s*ì•Œê³ ì‹¶)',
    ]
    
    for pattern in search_patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            keyword = match.group(1).strip()
            # ì¡°ì‚¬ ì œê±° (ì€/ëŠ”/ì´/ê°€/ì„/ë¥¼/ì—/ì˜ ë“±)
            keyword = re.sub(r'\s*(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ì—|ì˜|ì™€|ê³¼|ë¡œ|ìœ¼ë¡œ)\s*$', '', keyword)
            # "ê´€ë ¨", "ê´€í•œ", "ëŒ€í•œ" ê°™ì€ ë‹¨ì–´ ì œê±° (ê²€ìƒ‰ í‚¤ì›Œë“œì—ì„œ)
            keyword = re.sub(r'\s*(ê´€ë ¨|ê´€í•œ|ëŒ€í•œ|ëŒ€í•´|ê´€í•´)\s*$', '', keyword)
            keyword = re.sub(r'^\s*(ê´€ë ¨|ê´€í•œ|ëŒ€í•œ|ëŒ€í•´|ê´€í•´)\s*', '', keyword)
            if keyword and len(keyword) > 1:  # ìµœì†Œ 2ê¸€ì ì´ìƒ
                return True, keyword
    
    return False, ""


def detect_inappropriate_question(text: str) -> bool:
    """
    íˆ¬ì ì¡°ì–¸, ë¡œë˜ ë²ˆí˜¸ ë“± ë¶€ì ì ˆí•œ ì§ˆë¬¸ì¸ì§€ ê°ì§€í•©ë‹ˆë‹¤.
    
    Args:
        text: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        
    Returns:
        ë¶€ì ì ˆí•œ ì§ˆë¬¸ì´ë©´ True
    """
    if not text or not text.strip():
        return False
    
    text_lower = text.lower()
    
    # íˆ¬ì ì¡°ì–¸ ìš”ì²­ íŒ¨í„´
    investment_patterns = [
        r'ì–´ë””ì—.*íˆ¬ì|ì–´ë””.*íˆ¬ì|íˆ¬ì.*ì–´ë””|ì–´ë–¤.*íˆ¬ì|ë¬´ì—‡.*íˆ¬ì',
        r'íˆ¬ì.*ì¶”ì²œ|ì¶”ì²œ.*íˆ¬ì|íˆ¬ì.*ì–´ë•Œ|ì–´ë–»ê²Œ.*íˆ¬ì',
        r'ì£¼ì‹.*ì‚´ê¹Œ|ì‚´ê¹Œ.*ì£¼ì‹|ì–´ë–¤.*ì£¼ì‹|ë¬´ì—‡.*ì£¼ì‹',
        r'ì–´ë””.*ì‚´ê¹Œ|ë¬´ì—‡.*ì‚´ê¹Œ|ì–´ë–¤.*ì‚´ê¹Œ',
        r'ë¡œë˜.*ë²ˆí˜¸|ë²ˆí˜¸.*ë¡œë˜|ë¡œë˜.*ë½‘|ë½‘.*ë¡œë˜',
        r'ë³µê¶Œ.*ë²ˆí˜¸|ë²ˆí˜¸.*ë³µê¶Œ',
        r'ë‹¹ì²¨.*ë²ˆí˜¸|ë‹¹ì²¨.*ì˜ˆì¸¡',
        r'íˆ¬ì.*ì¡°ì–¸|ì¡°ì–¸.*íˆ¬ì|íˆ¬ì.*ìƒë‹´',
        r'ì–´ë–¤.*ì¢‹ì•„|ë¬´ì—‡.*ì¢‹ì•„|ì–´ë–¤ê²Œ.*ì¢‹ì•„',
        r'ì–´ë–¤.*ì‚¬|ë¬´ì—‡.*ì‚¬|ì–´ë–¤ê±°.*ì‚¬',
        r'.*ì—.*íˆ¬ìí• ê¹Œ|.*ì—.*íˆ¬ìí• ê¹Œí•´|.*ì—.*íˆ¬ìí• ê¹Œìš”|.*ì—.*íˆ¬ìí• ê¹Œìš”\?',
        r'.*ì—.*íˆ¬ì.*í• ê¹Œ|.*ì—.*íˆ¬ì.*í• ê¹Œí•´|.*ì—.*íˆ¬ì.*í• ê¹Œìš”',
    ]
    
    for pattern in investment_patterns:
        if re.search(pattern, text_lower):
            return True
    
    return False


def search_related_article(articles: list[dict], keyword: str) -> dict | None:
    """
    ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ê¸°ì‚¬ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    
    Args:
        articles: ë‰´ìŠ¤ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
        keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
        
    Returns:
        ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ê¸°ì‚¬ (ì—†ìœ¼ë©´ None)
    """
    if not articles or not keyword:
        return None
    
    keyword_lower = keyword.lower()
    best_match = None
    best_score = 0
    
    for article in articles:
        score = 0
        
        # ì œëª©ì—ì„œ ë§¤ì¹­ (ê°€ì¥ ë†’ì€ ì ìˆ˜)
        title = article.get("title", "").lower()
        if keyword_lower in title:
            score += 10
            # ì •í™•íˆ ì¼ì¹˜í•˜ë©´ ì¶”ê°€ ì ìˆ˜
            if keyword_lower == title:
                score += 5
        
        # ìš”ì•½ì—ì„œ ë§¤ì¹­
        summary = article.get("summary", "").lower()
        if keyword_lower in summary:
            score += 5
        
        # ë³¸ë¬¸ì—ì„œ ë§¤ì¹­
        content = article.get("content", "").lower()
        if keyword_lower in content:
            score += 2
            # ë³¸ë¬¸ì—ì„œ ì—¬ëŸ¬ ë²ˆ ë‚˜ì˜¤ë©´ ì¶”ê°€ ì ìˆ˜
            count = content.count(keyword_lower)
            if count > 1:
                score += min(count - 1, 3)  # ìµœëŒ€ 3ì  ì¶”ê°€
        
        # í‚¤ì›Œë“œì˜ ë‹¨ì–´ë“¤ì´ ê°ê° ë§¤ì¹­ë˜ëŠ”ì§€ í™•ì¸
        keyword_words = keyword_lower.split()
        if len(keyword_words) > 1:
            matched_words = sum(1 for word in keyword_words if word in title or word in summary)
            if matched_words > 0:
                score += matched_words * 2
        
        if score > best_score:
            best_score = score
            best_match = article
    
    # ìµœì†Œ ì ìˆ˜ ì´ìƒì´ì–´ì•¼ ë§¤ì¹­ìœ¼ë¡œ ì¸ì •
    if best_score >= 2:
        return best_match
    
    return None