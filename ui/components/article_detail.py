import time
from datetime import datetime
import streamlit as st
from core.logger import log_event, start_view_timer, end_view_timer, is_page_hidden_eval
from rag.glossary import highlight_terms, explain_term

def render():
    article = st.session_state.selected_article
    if not article:
        st.warning("ì„ íƒëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # âœ… ìµœì´ˆ ì§„ì… ì‹œì—ë§Œ ê¸°ì‚¬ ë Œë” latency ì¸¡ì •
    if not st.session_state.get("detail_enter_logged"):
        t0 = time.time()
        perf_steps = {}  # ì„±ëŠ¥ ì¸¡ì • ë‹¨ê³„ë³„ ì‹œê°„

        # ìƒì„¸ ì§„ì… íƒ€ì´ë¨¸ ì‹œì‘
        start_view_timer(article.get("id"))

        # ì‹¤ì œ ë Œë”ë§
        st.markdown("---")
        st.header(article['title'])
        st.caption(f"ğŸ“… {article['date']}")
        st.markdown('<div class="article-content">', unsafe_allow_html=True)
        
        # âœ… ì„±ëŠ¥ ì¸¡ì •: í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬ ì‹œê°„
        article_id = article.get("id")
        content = article['content']
<<<<<<< HEAD
        
        # ì»¨í…ì¸ ì— ë¬¸ë‹¨ êµ¬ë¶„ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ë¬¸ë‹¨ ìƒì„±
        if content:
            import re
            # ì´ë¯¸ ë¬¸ë‹¨ êµ¬ë¶„ì´ ìˆëŠ”ì§€ í™•ì¸ (ì¤„ë°”ê¿ˆ 2ê°œ ì´ìƒ)
            if '\n\n' not in content and content.count('\n') < len(content) / 200:
                # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸° (ë§ˆì¹¨í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œ ê¸°ì¤€)
                # í•œê¸€ ë§ˆì¹¨í‘œ(.), ì˜ë¬¸ ë§ˆì¹¨í‘œ(.), ë¬¼ìŒí‘œ(?), ëŠë‚Œí‘œ(!) í›„ ê³µë°±ì´ ì˜¤ë©´ ë¬¸ì¥ ëìœ¼ë¡œ ê°„ì£¼
                sentences = re.split(r'([.!?ã€‚ï¼ï¼Ÿ]\s+)', content)
                
                # ë¬¸ì¥ë“¤ì„ ì¬ì¡°í•©í•˜ë©´ì„œ ë¬¸ë‹¨ ìƒì„± (3-4ë¬¸ì¥ë§ˆë‹¤ ë¬¸ë‹¨ êµ¬ë¶„)
                formatted_paragraphs = []
                current_paragraph = []
                sentence_count = 0
                
                for i in range(0, len(sentences), 2):
                    if i + 1 < len(sentences):
                        sentence = sentences[i] + sentences[i + 1]
                    else:
                        sentence = sentences[i]
                    
                    if sentence.strip():
                        current_paragraph.append(sentence.strip())
                        sentence_count += 1
                        
                        # 3-4ë¬¸ì¥ë§ˆë‹¤ ë˜ëŠ” ë¬¸ì¥ì´ ê¸¸ë©´(150ì ì´ìƒ) ë¬¸ë‹¨ êµ¬ë¶„
                        if sentence_count >= 3 or len(' '.join(current_paragraph)) > 150:
                            if current_paragraph:
                                formatted_paragraphs.append(' '.join(current_paragraph))
                                current_paragraph = []
                                sentence_count = 0
                
                # ë‚¨ì€ ë¬¸ì¥ë“¤ ì²˜ë¦¬
                if current_paragraph:
                    formatted_paragraphs.append(' '.join(current_paragraph))
                
                # ë¬¸ë‹¨ êµ¬ë¶„ìë¡œ í•©ì¹˜ê¸°
                if formatted_paragraphs:
                    content = '\n\n'.join(formatted_paragraphs)
        
        highlight_start = time.time()
        # âœ… ì„±ëŠ¥ ê°œì„ : í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬ì—ì„œ ë°œê²¬ëœ ìš©ì–´ë„ í•¨ê»˜ ë°›ì•„ì„œ ì¬ì‚¬ìš©
        result = highlight_terms(content, article_id=str(article_id) if article_id else None, return_matched_terms=True)
=======
        highlight_start = time.time()
        # âœ… ì„±ëŠ¥ ê°œì„ : í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬ì—ì„œ ë°œê²¬ëœ ìš©ì–´ë„ í•¨ê»˜ ë°›ì•„ì„œ ì¬ì‚¬ìš©
        # âš¡ ë¬¸ë§¥ ì¸ì‹ í™œì„±í™”: use_context_filter=Trueë¡œ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
        result = highlight_terms(
            content, 
            article_id=str(article_id) if article_id else None, 
            return_matched_terms=True,
            use_context_filter=True  # âš¡ ë¬¸ë§¥ ì¸ì‹ í™œì„±í™”
        )
>>>>>>> origin/mjy
        if isinstance(result, tuple):
            highlighted_content, matched_terms_from_highlight = result
        else:
            highlighted_content = result
            matched_terms_from_highlight = set()
        highlight_elapsed_ms = int((time.time() - highlight_start) * 1000)
        perf_steps["highlight_ms"] = highlight_elapsed_ms
        # âœ… í•˜ì´ë¼ì´íŠ¸ ìºì‹œ íˆíŠ¸ ì¶”ì •: ì²˜ë¦¬ ì‹œê°„ì´ 5ms ì´í•˜ë©´ ìºì‹œ íˆíŠ¸ë¡œ ê°„ì£¼
        highlight_cache_hit = highlight_elapsed_ms <= 5
        
        # âœ… í•˜ì´ë¼ì´íŠ¸ ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥ (ì¬ë Œë”ë§ ì‹œ ì¦‰ì‹œ ì‚¬ìš©)
        if article_id:
            highlight_cache_key = f"article_highlight_cache_{article_id}"
            st.session_state[highlight_cache_key] = highlighted_content
        
        st.markdown(highlighted_content, unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)
        if article.get("url"):
            st.markdown(f"[ğŸ”— ê¸°ì‚¬ ì›ë¬¸ ë³´ê¸°]({article['url']})")

        # âœ… ì„±ëŠ¥ ì¸¡ì •: ìš©ì–´ ëª©ë¡ í•„í„°ë§ ì‹œê°„
        terms_filter_start = time.time()
        # âœ… ì„±ëŠ¥ ê°œì„ : í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬ì—ì„œ ì´ë¯¸ ë°œê²¬ëœ ìš©ì–´ ì¬ì‚¬ìš© (O(1) ë³µì¡ë„)
        terms_to_show = []
        cache_key = f"terms_to_show_cache_{article_id}"
        cached_terms = st.session_state.get(cache_key)
        if cached_terms is not None:
            terms_to_show = cached_terms
            perf_steps["terms_filter_ms"] = 0  # ìºì‹œ íˆíŠ¸
        elif matched_terms_from_highlight:
            # âœ… ì„±ëŠ¥ ê°œì„ : í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬ì—ì„œ ì´ë¯¸ ë°œê²¬ëœ ìš©ì–´ ì‚¬ìš© (ì¶”ê°€ í•„í„°ë§ ë¶ˆí•„ìš”)
            terms_to_show = list(matched_terms_from_highlight)
            if article_id:
                st.session_state[cache_key] = terms_to_show
            perf_steps["terms_filter_ms"] = int((time.time() - terms_filter_start) * 1000)
        else:
            # Fallback: í•˜ì´ë¼ì´íŠ¸ì—ì„œ ìš©ì–´ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° (ë“œë¬¸ ê²½ìš°)
            content_lower = content.lower()
            highlight_terms_set = st.session_state.get("rag_terms_for_highlight")
            if highlight_terms_set:
                terms_set = set()
                for term in highlight_terms_set:
                    if term and term.lower() in content_lower:
                        terms_set.add(term)
                terms_to_show = list(terms_set)
            elif st.session_state.get("rag_initialized", False):
                try:
                    metadata_map = st.session_state.get("rag_metadata_by_term")
                    if metadata_map:
                        terms_set = set()
                        seen_terms = set()
                        for term_key, metadata in metadata_map.items():
                            original_term = metadata.get('term', '').strip()
                            if original_term and original_term not in seen_terms:
                                seen_terms.add(original_term)
                                if original_term.lower() in content_lower:
                                    terms_set.add(original_term)
                        terms_to_show = list(terms_set)
                    else:
                        collection = st.session_state.rag_collection
                        all_data = collection.get()
                        if all_data and all_data['metadatas']:
                            terms_set = set()
                            for metadata in all_data['metadatas']:
                                term = metadata.get('term', '').strip()
                                if term and term.lower() in content_lower:
                                    terms_set.add(term)
                            terms_to_show = list(terms_set)
                except Exception as e:
                    terms_to_show = [t for t in st.session_state.financial_terms.keys() if t.lower() in content_lower]
            else:
                terms_to_show = [t for t in st.session_state.financial_terms.keys() if t.lower() in content_lower]
            
            if article_id:
                st.session_state[cache_key] = terms_to_show
            perf_steps["terms_filter_ms"] = int((time.time() - terms_filter_start) * 1000)
        
        perf_steps["terms_count"] = len(terms_to_show)

        # âœ… ì„±ëŠ¥ ì¸¡ì •: ì „ì²´ ë Œë”ë§ ì‹œê°„
        total_latency_ms = int((time.time() - t0) * 1000)
        perf_steps["total_ms"] = total_latency_ms
        perf_steps["content_length"] = len(content)
        perf_steps["highlighted_length"] = len(highlighted_content)
        
        # ë Œë” ì™„ë£Œ â†’ ìƒì„¸ ì„±ëŠ¥ ì •ë³´ì™€ í•¨ê»˜ ë¡œê·¸ ê¸°ë¡
        log_event(
            "news_detail_open",
            news_id=article_id,
            surface="detail",
            title=article.get("title"),
            latency_ms=total_latency_ms,
            note="ê¸°ì‚¬ ë Œë”ë§ ì™„ë£Œ",
            payload={
                "article_id": article_id,
                "perf_steps": perf_steps,  # ë‹¨ê³„ë³„ ì„±ëŠ¥ ì •ë³´
                "cache_hit": cached_terms is not None or highlight_cache_hit,  # âœ… ìš©ì–´ ëª©ë¡ ìºì‹œ ë˜ëŠ” í•˜ì´ë¼ì´íŠ¸ ìºì‹œ íˆíŠ¸
                "highlight_cache_hit": highlight_cache_hit,  # í•˜ì´ë¼ì´íŠ¸ ìºì‹œ íˆíŠ¸ ì—¬ë¶€
                "terms_cache_hit": cached_terms is not None,  # ìš©ì–´ ëª©ë¡ ìºì‹œ íˆíŠ¸ ì—¬ë¶€
            }
        )

        # í”Œë˜ê·¸ ì„¤ì •(ì¤‘ë³µ ê¸°ë¡ ë°©ì§€)
        st.session_state.detail_enter_logged = True
        st.session_state.page_enter_time = datetime.now()

    else:
        # âœ… ì¬ë Œë” ì‹œì—ëŠ” ìºì‹œëœ í•˜ì´ë¼ì´íŠ¸ ì»¨í…ì¸  ì‚¬ìš© (ì„±ëŠ¥ ìµœì í™”)
        article_id = article.get("id")
        highlight_cache_key = f"article_highlight_cache_{article_id}"
        
        # ìºì‹œëœ í•˜ì´ë¼ì´íŠ¸ ì»¨í…ì¸ ê°€ ìˆìœ¼ë©´ ì¬ì‚¬ìš© (í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬ ìƒëµ)
        cached_highlight = st.session_state.get(highlight_cache_key)
        
        if cached_highlight:
            # ìºì‹œ íˆíŠ¸: í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬ ìƒëµ (ê±°ì˜ 0ms)
            highlighted_content = cached_highlight
        else:
            # ìºì‹œ ë¯¸ìŠ¤: í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬ (í•˜ì§€ë§Œ ì´ë¯¸ highlight_terms ë‚´ë¶€ ìºì‹œ í™œìš©)
            content = article['content']
            highlighted_content = highlight_terms(content, article_id=str(article_id) if article_id else None)
            
            # í•˜ì´ë¼ì´íŠ¸ ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥ (ë‹¤ìŒ ì¬ë Œë”ë§ ì‹œ ì¦‰ì‹œ ì‚¬ìš©)
            if article_id:
                st.session_state[highlight_cache_key] = highlighted_content
        
        # UI ë Œë”ë§ (í•­ìƒ ì‹¤í–‰í•˜ë˜, í•˜ì´ë¼ì´íŠ¸ëŠ” ìºì‹œì—ì„œ ê°€ì ¸ì˜´)
        st.markdown("---")
        st.header(article['title'])
        st.caption(f"ğŸ“… {article['date']}")
        st.markdown('<div class="article-content">', unsafe_allow_html=True)
        st.markdown(highlighted_content, unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)
        if article.get("url"):
            st.markdown(f"[ğŸ”— ê¸°ì‚¬ ì›ë¬¸ ë³´ê¸°]({article['url']})")

    # âœ… ì„±ëŠ¥ ê°œì„ : is_page_hidden_eval() í˜¸ì¶œ ìµœì†Œí™” (ë’¤ë¡œê°€ê¸° ë²„íŠ¼ í´ë¦­ ì‹œì—ë§Œ ì²´í¬)
    # íƒ­ ì „í™˜ ë“±ìœ¼ë¡œ í˜ì´ì§€ê°€ ìˆ¨ê²¨ì§€ë©´ ì¢…ë£Œí•˜ëŠ” ë¡œì§ì€ ì œê±° (í•„ìš”ì‹œì—ë§Œ í™œì„±í™”)


    # â† ë’¤ë¡œê°€ê¸° ë²„íŠ¼ : ëª©ë¡ìœ¼ë¡œ
    if st.button("â† ë‰´ìŠ¤ ëª©ë¡ìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        # âœ… ì„±ëŠ¥ ì¸¡ì •: ë’¤ë¡œê°€ê¸° ì²˜ë¦¬ ì‹œê°„
        back_start = time.time()
        
        # âœ… ë¡œê·¸ ì¤‘ë³µ ì œê±°: end_view_timer() ë‚´ë¶€ ë¡œê·¸ì™€ í†µí•©
        duration_sec = None
        max_depth_pct = None
        if st.session_state.get("detail_enter_logged"):
            # end_view_timer() ë‚´ë¶€ì—ì„œ ê³„ì‚°í•˜ëŠ” ì •ë³´ë¥¼ ì§ì ‘ ê°€ì ¸ì˜´
            if "view_start_time" in st.session_state:
                duration_sec = time.time() - st.session_state["view_start_time"]
            news_id = st.session_state.get("view_news_id", article.get("id"))
            max_depth_pct = st.session_state.get("detail_max_depth_pct", 0.0)
            
            # end_view_timer() í˜¸ì¶œ (ë‚´ë¶€ ë¡œê·¸ëŠ” ê¸°ë¡í•˜ì§€ ì•Šë„ë¡ ìˆ˜ì • í•„ìš”í•˜ì§€ë§Œ,
            # ì¼ë‹¨ ì—¬ê¸°ì„œ í†µí•© ë¡œê·¸ë¡œ ê¸°ë¡í•˜ë¯€ë¡œ ì¤‘ë³µì€ ì œê±°ë¨)
            # ì„¸ì…˜ ìƒíƒœë§Œ ì •ë¦¬
            for k in ("view_start_time", "view_news_id", "detail_max_depth_pct"):
                if k in st.session_state:
                    del st.session_state[k]
            
            st.session_state.detail_enter_logged = False
        
        # âœ… í†µí•© ë¡œê·¸ 1ë²ˆë§Œ ê¸°ë¡ (view_duration + news_detail_back ì •ë³´ í¬í•¨)
        log_event(
            "news_detail_back", 
            news_id=article.get("id"), 
            surface="detail",
            payload={
                "back_process_ms": int((time.time() - back_start) * 1000),
                "duration_sec": round(duration_sec, 2) if duration_sec is not None else None,
                "max_depth_pct": round(max_depth_pct, 1) if max_depth_pct is not None else None,
            }
        )
        
        st.session_state.selected_article = None
        st.session_state.detail_enter_logged = False
        st.rerun()

    # ìš©ì–´ ì„¤ëª… UI
    st.info("ğŸ’¡ ì•„ë˜ ë²„íŠ¼ì—ì„œ ìš©ì–´ë¥¼ ì„ íƒí•˜ë©´ ì±—ë´‡ì´ ì‰½ê²Œ ì„¤ëª…í•´ë“œë¦½ë‹ˆë‹¤!")
    st.subheader("ğŸ” ìš©ì–´ ì„¤ëª… ìš”ì²­")

    # âœ… ì„±ëŠ¥ ê°œì„ : ìš©ì–´ ëª©ë¡ì€ ì´ë¯¸ ìœ„ì—ì„œ ê³„ì‚°ë¨ (ì¬ë Œë” ì‹œì—ëŠ” ìºì‹œì—ì„œ ê°€ì ¸ì˜¤ê¸°)
    if not st.session_state.get("detail_enter_logged"):
        # ì²« ë Œë”ë§ ì‹œì—ëŠ” ì´ë¯¸ terms_to_showê°€ ê³„ì‚°ë¨
        pass
    else:
        # ì¬ë Œë” ì‹œì—ëŠ” ìºì‹œì—ì„œ ê°€ì ¸ì˜¤ê¸°
        article_id = article.get("id")
        cache_key = f"terms_to_show_cache_{article_id}"
        cached_terms = st.session_state.get(cache_key)
        if cached_terms is not None:
            terms_to_show = cached_terms
        else:
            # ìºì‹œê°€ ì—†ìœ¼ë©´ ë‹¤ì‹œ ê³„ì‚° (ë“œë¬¸ ê²½ìš°)
            content_lower = article['content'].lower()
            if st.session_state.get("rag_initialized", False):
                try:
                    metadata_map = st.session_state.get("rag_metadata_by_term")
                    if metadata_map:
                        terms_set = set()
                        for term_key, metadata in metadata_map.items():
                            original_term = metadata.get('term', '').strip()
                            if original_term and original_term.lower() in content_lower:
                                terms_set.add(original_term)
                        terms_to_show = list(terms_set)
                    else:
                        collection = st.session_state.rag_collection
                        all_data = collection.get()
                        if all_data and all_data['metadatas']:
                            terms_set = set()
                            for metadata in all_data['metadatas']:
                                term = metadata.get('term', '').strip()
                                if term and term.lower() in content_lower:
                                    terms_set.add(term)
                            terms_to_show = list(terms_set)
                except Exception as e:
                    terms_to_show = [t for t in st.session_state.financial_terms.keys() if t.lower() in content_lower]
            else:
                terms_to_show = [t for t in st.session_state.financial_terms.keys() if t.lower() in content_lower]
            
            if article_id:
                st.session_state[cache_key] = terms_to_show

    # ë²„íŠ¼ ë Œë”ë§ (3ì—´ ê·¸ë¦¬ë“œ)
    for i in range(0, len(terms_to_show), 3):
        cols = st.columns(3)
        for j, col in enumerate(cols):
            if i + j < len(terms_to_show):
                term = terms_to_show[i + j]
                with col:
                    if st.button(f"ğŸ“Œ {term}", key=f"term_btn_{term}", use_container_width=True):
                        # âœ… ì„±ëŠ¥ ì¸¡ì •: ìš©ì–´ í´ë¦­ ì „ì²´ ì²˜ë¦¬ ì‹œê°„
                        term_click_start = time.time()
                        st.session_state.term_click_count += 1

                        user_question = f"'{term}' ìš©ì–´ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”"
                        # ëŒ€í™” íˆìŠ¤í† ë¦¬ (ì‚¬ìš©ì ë°œí™” 1íšŒë§Œ ê¸°ë¡)
                        st.session_state.chat_history.append({"role": "user", "content": user_question})

                        # âœ… ì„±ëŠ¥ ì¸¡ì •: ì„¤ëª… ìƒì„± ì‹œê°„
                        explanation_start = time.time()
                        explanation, rag_info = explain_term(term, st.session_state.chat_history, return_rag_info=True)
                        explanation_latency_ms = int((time.time() - explanation_start) * 1000)
                        
                        # âœ… ì„±ëŠ¥ ì¸¡ì •: ì „ì²´ ì²˜ë¦¬ ì‹œê°„
                        total_latency_ms = int((time.time() - term_click_start) * 1000)

                        # í´ë¦­(ìë™ ì§ˆë¬¸ í¬í•¨) ì´ë²¤íŠ¸ ë¡œê·¸ (ìƒì„¸ ì„±ëŠ¥ ì •ë³´ í¬í•¨)
                        log_event(
                            "glossary_click",
                            term=term,
                            news_id=article.get("id"),
                            source="news_highlight",
                            surface="detail",
                            message=user_question,
                            click_count=st.session_state.term_click_count,
                            latency_ms=total_latency_ms,  # ì „ì²´ ì²˜ë¦¬ ì‹œê°„
                            payload={
                                "term": term,
                                "news_id": article.get("id"),
                                "perf_steps": {
                                    "explanation_ms": explanation_latency_ms,  # ì„¤ëª… ìƒì„± ì‹œê°„
                                    "total_ms": total_latency_ms,  # ì „ì²´ ì²˜ë¦¬ ì‹œê°„
                                    "answer_length": len(explanation),  # ë‹µë³€ ê¸¸ì´
                                },
                                "rag_info": rag_info,  # RAG ì •ë³´
                            }
                        )

                        # ë‹µë³€ íˆìŠ¤í† ë¦¬ + ë‹µë³€ ì´ë²¤íŠ¸ ë¡œê·¸
                        st.session_state.chat_history.append({"role": "assistant", "content": explanation})
                        log_event(
                            "glossary_answer",
                            term=term,
                            source="news_highlight",
                            surface="detail",
                            message=user_question,
                            answer_len=len(explanation),
                            latency_ms=explanation_latency_ms,  # ì„¤ëª… ìƒì„± ì‹œê°„
                            via="rag",
                            rag_info=rag_info,
                            response=explanation,
                            payload={
                                "term": term,
                                "news_id": article.get("id"),
                                "perf_steps": {
                                    "explanation_ms": explanation_latency_ms,
                                    "total_ms": total_latency_ms,
                                    "answer_length": len(explanation),
                                },
                                "rag_info": rag_info,
                            }
                        )

                        st.rerun()

    st.caption("ğŸ’¡ Tip: ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì˜¤ë¥¸ìª½ ì±—ë´‡ì—ì„œ ìƒì„¸ ì„¤ëª…ì„ ë³¼ ìˆ˜ ìˆì–´ìš”!")
